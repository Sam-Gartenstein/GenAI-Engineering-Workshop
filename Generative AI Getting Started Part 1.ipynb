{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj3g3cSvgSMTVKMjLpb9CC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Generative%20AI%20Getting%20Started%20Part%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Beginner‚Äôs Guide to OpenAI in Google Colab\n",
        "\n",
        "Welcome to **Part 1: Beginner‚Äôs Guide to OpenAI in Google Colab**. In this notebook, you‚Äôll learn the fundamentals of **prompt engineering** through a step-by-step tutorial. By the end, you‚Äôll be able to:\n",
        "\n",
        "- Create and store an OpenAI API key  \n",
        "- Apply core prompt engineering strategies (iteration and refinement)  \n",
        "- Use practical coding patterns to streamline your workflow  \n",
        "\n",
        "These skills are not only valuable for this project, but they will also help you stand out in industry. In fact, Andrew Ng [notes](https://www.linkedin.com/posts/andrewyng_there-is-significant-unmet-demand-for-developers-activity-7369397355160272898-i85T?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAUuuFIBPjBR1kCVBdoY03J3r6hwaAwvapU) that some of the key abilities he looks for when interviewing AI engineers include:  \n",
        "\n",
        "- Using AI building blocks like prompting, RAG, evals, agentic workflows, and machine learning to build applications  \n",
        "- Prototyping and iterating rapidly  \n",
        "\n",
        "You‚Äôll get to practice both of these in this workshop.  \n",
        "\n",
        "Let‚Äôs dive in and start building! üöÄ\n",
        "\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "h0D-mCSmF4fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. Getting Started with OpenAI\n",
        "\n",
        "    - Step 1: OpenAI\n",
        "\n",
        "    - Step 2: Authentication\n",
        "\n",
        "    - Step 3: Creating a New Secret Key\n",
        "\n",
        "    - Step 4: Creating the Key\n",
        "\n",
        "    - Step 5: Saving Your Key\n",
        "\n",
        "    - Next Steps\n",
        "\n",
        "2. Saving Your API Key in Colab\n",
        "\n",
        "3. Loading and Veriyfing your Key üîë\n",
        "\n",
        "4. Prompt Engineering Tips\n",
        "    \n",
        "    - Adding More Detail\n",
        "\n",
        "    - Controlling Length\n",
        "\n",
        "    - Guide Style\n",
        "\n",
        "    - Consistent Structure\n",
        "\n",
        "    - Role Prompting\n",
        "\n",
        "5. Don‚Äôt Repeat Yourself (DRY) Programming - Creating Functions\n",
        "\n",
        "6. Role Prompting (System/User)\n",
        "\n",
        "7. Temperature\n",
        "\n",
        "   - Temperature 0.2\n",
        "\n",
        "   - Temperature 1.8\n",
        "\n",
        "8. Markdown Formatting\n",
        "\n",
        "9. Forward\n",
        "\n",
        "-----\n"
      ],
      "metadata": {
        "id": "a3TFltMM6-BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting Started with OpenAI</h2>\n",
        "\n",
        "In this notebook, we will help you get started working with OpenAI's API.  \n"
      ],
      "metadata": {
        "id": "9DOXu1ULLQ-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: OpenAI  \n",
        "\n",
        "Click this link to open [OpenAI](https://openai.com/). In the top-right corner, hover over **Log In** and select **API Platform**, as shown in the image below.  \n"
      ],
      "metadata": {
        "id": "NcAUE-qhMoqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_1.png?raw=true\">"
      ],
      "metadata": {
        "id": "SWmQGCh95aah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Authentication  \n",
        "\n",
        "After signing in (and entering the verification code sent to your email), you will be directed to the page shown below. Under **Authentication**, click <u>Organization settings</u>.  \n"
      ],
      "metadata": {
        "id": "8ai80iO7MtjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_2.png?raw=true\">"
      ],
      "metadata": {
        "id": "fvmIkb_K5dQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Creating a New Secret Key  \n",
        "\n",
        "After clicking <u>Organization settings</u>, you will be taken to the page shown below. From there, click **Create new secret key**.  \n"
      ],
      "metadata": {
        "id": "9ASw4lDf4qSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_3.png?raw=true\">"
      ],
      "metadata": {
        "id": "mAKiVFJ_5Bvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Creating the Key  \n",
        "\n",
        "After clicking **Create new secret key**, a pop-up will appear. While entering a name is optional, it is recommended to use something meaningful (e.g., *Fall 2025 Practicum*). Next, select **Default project** and ensure **All** is selected. Finally, click **Create secret key**.  \n"
      ],
      "metadata": {
        "id": "3aT5Qh835c1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_4.png?raw=true\">"
      ],
      "metadata": {
        "id": "-ZbPe1Rz557Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Saving Your Key  \n",
        "\n",
        "After creating the key, it will appear as shown below (mine is hidden for privacy).  \n",
        "\n",
        "1. Click **Copy** and save your key somewhere safe‚Äîyou won‚Äôt be able to view it again later.  \n",
        "2. Do **not** share your key. Using an OpenAI key incurs costs, and you will be charged if someone else uses it.  "
      ],
      "metadata": {
        "id": "MfzG8I2V5b0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_5.png?raw=true\">"
      ],
      "metadata": {
        "id": "Qdi0Mg3_56wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps\n",
        "\n",
        "Congrats! You now made your OpenAI Key. Now, this is where the fun part begins. We can finally utilize the key.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "YGNlDDkN5w1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Saving Your API Key in Colab üîë\n",
        "\n",
        "Before using OpenAI's API, we need a secure way to store the API key in this notebook.  \n",
        "Google Colab provides a built-in secrets manager for this purpose.  \n",
        "\n",
        "\n",
        "### Step 1:\n",
        "On the left sidebar, click on the **key icon**.  \n",
        "\n",
        "### Step 2:\n",
        "Click **‚ÄúAdd new secret.‚Äù**  \n",
        "\n",
        "### Step 3:\n",
        "- Paste your API key into the **Value** field  \n",
        "- Give it a descriptive **Name** (e.g., `OPENAI_API_KEY`)  \n",
        "- Ensure **Notebook access** is enabled  \n"
      ],
      "metadata": {
        "id": "Bu1FZjF_62yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_6.png?raw=true\" width=\"500\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "GVvXAhCE-3MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Once entered, you can hit the exit button. Your API key will be  stored automatically and available for use in your notebook.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "nqBl6zeD-2Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading and Verifying Your API Key üîë\n",
        "\n",
        "We load the API key from Colab Secrets into an environment variable so Python packages can access it.  \n",
        "The check then verifies whether `OPENAI_API_KEY` is set:  \n",
        "\n",
        "- If the key is missing, a clear **RuntimeError** is raised so you know to add it in Colab Secrets.  \n",
        "- If the key is found, it safely confirms with `True` without ever printing the actual secret.  \n",
        "\n",
        "However, before we do this, we must import `openai`'s library.\n",
        "\n",
        "<br>  \n",
        "\n",
        "**‚ú® Optional Learning**  \n",
        "- `google.colab.userdata`: Secure interface to Colab‚Äôs Secrets; lets you fetch saved keys (e.g., `userdata.get(\"OPENAI_API_KEY\")`).  \n",
        "- `os`: Standard library module for interacting with the operating system ‚Äî here, used to read/set environment variables (`os.getenv`, `os.environ`).  "
      ],
      "metadata": {
        "id": "ISid8s8DDBKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "hHEhlVltMWup"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Pull your saved secret into an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Test if the key is available (without printing it)\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise RuntimeError(\"OPENAI_API_KEY is not set. Add it via Colab Secrets (üîë) and try again.\")\n",
        "else:\n",
        "    print(\"Key loaded?\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dxACnFdC8Nj",
        "outputId": "7a30399c-904e-49eb-dff7-43c7caead3c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key loaded? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "If you see `Key loaded? True`, then everything is working and you‚Äôre ready to move on to the next step.  \n",
        "\n",
        "<br>\n",
        "\n",
        "If you see the error, please make sure that:  \n",
        "- You saved your API key in Colab‚Äôs **üîë Secrets** panel.  \n",
        "- The secret is named exactly **`OPENAI_API_KEY`** (no typos or extra spaces).  \n",
        "\n"
      ],
      "metadata": {
        "id": "nErn9WnmH8KT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats! If you have successfully loaded in your key, you will run your first **end-to-end test with the OpenAI API** ‚Äî creating a client, sending a simple prompt, and viewing the model‚Äôs reply.  \n",
        "\n",
        "The first line\n",
        "\n",
        "```python\n",
        "client = OpenAI() `\n",
        "```\n",
        "\n",
        "Creates an OpenAI client that knows how to talk to the API. It automatically picks up your API key from `OPENAI_API_KEY`, which you saved earlier in Colab‚Äôs Secrets.\n",
        "\n",
        "The next three lines:\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "```\n",
        "\n",
        "- Sends a **request** to the Responses API\n",
        "- `model=\"gpt-4o-mini\"` selects the model\n",
        "- `input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"` is your prompt\n",
        "- The full structured result (text + metadata) is stored in `resp`\n",
        "\n",
        "Finally:\n",
        "\n",
        "```python\n",
        "print(resp.output_text)\n",
        "```\n",
        "\n",
        "Extracts just the generated text from the response object and prints it.\n",
        "\n",
        "<br>\n",
        "\n",
        "That‚Äôs it! We follow this process: create a client ‚Üí send a prompt ‚Üí print the model‚Äôs reply."
      ],
      "metadata": {
        "id": "115lW5IyJS4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()  # uses OPENAI_API_KEY already in your env\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu1AeBQBC_0o",
        "outputId": "3c741532-c329-4054-c87f-f6ba17e380ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some concise study tips:\n",
            "\n",
            "1. **Set Clear Goals**: Define what you want to achieve in each study session, whether it‚Äôs completing a chapter or understanding a concept. This gives your study time focus.\n",
            "\n",
            "2. **Use Active Learning**: Engage with the material by summarizing information in your own words, teaching it to someone else, or discussing it with peers. This reinforces understanding.\n",
            "\n",
            "3. **Break It Down**: Divide your study material into smaller, manageable sections. Tackle them one at a time to prevent feeling overwhelmed and improve retention.\n",
            "\n",
            "4. **Space Your Study Sessions**: Instead of cramming, space out your study sessions over several days or weeks. This technique, known as spaced repetition, enhances long-term retention.\n",
            "\n",
            "5. **Stay Organized**: Keep your notes, resources, and study materials organized. Use folders, apps, or planners to track assignments and deadlines to avoid last-minute stress.\n",
            "\n",
            "6. **Use Visual Aids**: Incorporate diagrams, charts, and mind maps to visualize concepts. This can make complex information simpler and easier to remember.\n",
            "\n",
            "7. **Practice Retrieval**: Regularly test yourself on what you‚Äôve learned by using flashcards or practice quizzes. This reinforces your memory and identifies areas that need more focus.\n",
            "\n",
            "8. **Minimize Distractions**: Create a conducive study environment by finding a quiet space, turning off notifications, and limiting interruptions for better concentration.\n",
            "\n",
            "9. **Stay Healthy**: Prioritize sleep, nutrition, and exercise. A healthy body contributes to a sharper mind, improving focus and cognitive function.\n",
            "\n",
            "10. **Stay Positive**: Keep a positive mindset. Celebrate your progress and acknowledge your efforts, as a good attitude can enhance motivation and resilience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "## 4. Prompt Engineering Tips  \n",
        "\n",
        "Congrats! You just used OpenAI‚Äôs API to prompt üéâ You‚Äôre a pro already! However, like any good pro, there‚Äôs always room for improvement.  \n",
        "\n",
        "While the output may look fine, our prompt is actually **‚Äúfluffy.‚Äù** It leaves too much room for interpretation ‚Äî words like *‚Äúfairly short‚Äù* or *‚Äúa few sentences‚Äù* are vague and can lead to inconsistent or overly long responses.  \n",
        "\n",
        "To fix this, we turn to **prompt engineering**. By carefully shaping your prompt, you can guide the model to produce responses that are **shorter, more specific, and better formatted**.  \n",
        "\n",
        "A few helpful strategies:  \n",
        "- **Be precise**: Reduce ‚Äúfluffy‚Äù or vague descriptions in your prompt.  \n",
        "- **Set boundaries**: Specify the number of items you want (e.g., ‚ÄúGive me 3 tips‚Äù).  \n",
        "- **Control format**: Ask for bullet points, numbered lists, or concise sentences.  \n",
        "- **Guide style**: Indicate the tone or audience (‚ÄúExplain this like I‚Äôm a high school student‚Äù).  \n",
        "\n",
        "With these small adjustments, you gain much more control over the **length, style, and clarity** of the output.  \n",
        "\n",
        "<br>\n",
        "\n",
        "Let‚Äôs start by reducing the **‚Äúfluffy‚Äù** description. Instead of leaving things vague, we‚Äôll make the prompt more precise and test how that changes the output.\n"
      ],
      "metadata": {
        "id": "oJWnJsB4O7to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me three concise study tips. The output should be bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7yhFEkZKp7k",
        "outputId": "6e975dc4-fd49-4eb9-9fd8-2ce709b7671c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Active Recall:** Test yourself regularly on the material to reinforce memory and understanding.\n",
            "- **Spaced Repetition:** Review information at increasing intervals to enhance retention over time.\n",
            "- **Interleaved Practice:** Mix different subjects or types of problems in a single study session to improve learning outcomes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding More Detail\n",
        "\n",
        "Nice! We guided the model to generate only three points. We set a **boundary** and **controlled** the format! Now, let‚Äôs refine the prompt further by adding more detail about how each tip should look. Although the original output may be sentences, since we **DID NOT** specify this originally, lets ensure that they are always outputted as sentences.\n"
      ],
      "metadata": {
        "id": "EDMad53OVkVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me exactly 3 study tips, each in one sentence. Format the output as bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeo2f8otToNy",
        "outputId": "68391e76-d441-4a2f-a90d-7d007510fe74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Break your study sessions into focused intervals, such as 25 minutes of work followed by a 5-minute break, to enhance concentration and retention.  \n",
            "- Utilize active learning techniques, such as summarizing material in your own words or teaching concepts to someone else, to deepen understanding.  \n",
            "- Create a dedicated, organized study space free from distractions to improve focus and productivity while studying.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Controlling Length  \n",
        "\n",
        "Great! We added another instruction to the prompt, telling the model that each tip should be one sentence. However, you may notice that some of the tips are still quite long. To tighten things up even more, we can add another constraint: limit each tip to **20 words or fewer**.  \n"
      ],
      "metadata": {
        "id": "FJfy5nqhX_68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me exactly 3 study tips. Each tip should be one sentence (‚â§ 20 words). Format as bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coVJMmzsTocm",
        "outputId": "625c5c9d-0d33-4338-d2da-6ebb7168f05f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Use active recall by testing yourself on the material instead of just re-reading notes.  \n",
            "- Create a study schedule to break down subjects into manageable, focused sessions.  \n",
            "- Teach the material to someone else to reinforce your understanding and retention.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guide Style  \n",
        "\n",
        "Great! Now we‚Äôve made our tips more concise. But we can also **tailor them to a specific audience or context**. After all, not every subject will require the same study strategies.  \n",
        "\n",
        "Let‚Äôs adjust the prompt to target a particular audience ‚Äî for example, students in a **college-level introductory statistics course**. Along with our earlier instructions (exactly 3 tips, one sentence each, ‚â§ 20 words, formatted as bullet points), we‚Äôll also ask the model to be **concrete and domain-specific** by referencing ideas like *sampling, probability, or hypothesis testing*.  \n",
        "\n",
        "**Concept:** Notice the `\\n` in the prompt. This adds a line break inside the string, making multi-step instructions clearer for both you and the model.  \n"
      ],
      "metadata": {
        "id": "aCANEu7FZlJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\n",
        "        \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "        \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "        \"Format as bullet points.\\n\"\n",
        "        \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo7ErNYyX63A",
        "outputId": "7219adf8-36eb-46be-f05a-112472b5ef30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Practice solving problems related to different sampling methods to understand their impact on data collection and analysis.  \n",
            "- Familiarize yourself with probability concepts by working on real-life examples, such as calculating probabilities in games or surveys.  \n",
            "- Conduct mock hypothesis tests using sample data to reinforce understanding of p-values and statistical significance principles.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consistent Structure  \n",
        "\n",
        "Look at that! We‚Äôve created three amazing study tips! Well, GPT did ‚Äî but it couldn‚Äôt have done it without our help and thoughtful prompting.  \n",
        "\n",
        "However, you may notice that the **formatting isn‚Äôt always consistent** after running the prompt. Sometimes the model adds a **tip title** (e.g., **Active Recall**) before the explanation, while other times it just writes the explanation itself.  \n",
        "\n",
        "To improve readability, we can adjust our prompt to request a **consistent structure** ‚Äî for example, always starting with a bolded tip title followed by a short explanation. One effective way to do this is with **one-shot prompting**, where we include a single example for the model to imitate.  \n"
      ],
      "metadata": {
        "id": "lvQccyHzftAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\n",
        "        \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "        \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "        \"Format as bullet points.\\n\"\n",
        "        \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\\n\"\n",
        "        \"\\n\"\n",
        "        \"Example (match structure exactly):\\n\"\n",
        "        \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "        \"\\n\"\n",
        "        \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nb54ZiZgX66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d37850-09e1-4841-f24e-bd2ad864c2d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ä¢ **Practice Problems:** Work through varied practice problems on hypothesis testing to solidify your understanding and application skills.\n",
            "\n",
            "‚Ä¢ **Visual Aids:** Create visual representations like graphs or charts for concepts such as normal distribution and sampling methods.\n",
            "\n",
            "‚Ä¢ **Study Groups:** Join a study group to discuss key concepts like p-values and confidence intervals for collaborative learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üéâ Congrats! You‚Äôre well on your way to becoming a prompt engineering pro!  \n",
        "\n",
        "As you‚Äôve seen, this is an **iterative process** ‚Äî each step builds on the last, and small adjustments to your instructions can lead to big improvements in the model‚Äôs output.  \n",
        "\n",
        "Let‚Äôs keep building on this strong foundation!\n",
        "\n"
      ],
      "metadata": {
        "id": "vLmi7a9d5N8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Role Prompting\n",
        "\n",
        "Now let‚Äôs take things a step further with **role prompting**. So far, we‚Äôve shaped the *content* and *format* of the output. We can also influence the **voice, style, and perspective** by assigning the model a role.\n",
        "\n",
        "For example, telling the model *‚ÄúYou are an encouraging tutor‚Äù* leads to friendlier tips, while *‚ÄúYou are a harsh and strict tutor‚Äù* yields a more formal and demanding style.\n",
        "\n",
        "By experimenting with roles, you can align responses with your audience or use case. We‚Äôll also apply good practices: control length, guide style, and maintain a consistent structure through one-shot prompting.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Tips:**\n",
        "- As prompts get longer, assign the text to a variable and pass it to the model.\n",
        "- Save the model‚Äôs output as a variable (a string) for later use.\n"
      ],
      "metadata": {
        "id": "jpPeYVXfIhCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouraging_prompt = (\n",
        "    \"You are an encouraging tutor. Use supportive and positive language. \"\n",
        "    \"Adopt this encouraging voice consistently in every tip.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip must be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Celebrate progress by testing yourself with short quizzes on sampling and probability after each session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, written in the same format but with the encouraging tone.\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input= encouraging_prompt\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdBRuI_oIxpA",
        "outputId": "c5e1c6b4-2ed3-4ed0-db32-52d08b637518"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolutely! Here are three more encouraging tips for your statistics studies:\n",
            "\n",
            "- **Visual Aids:** Create colorful charts and graphs to visualize data distributions, making concepts like normal curves more engaging and memorable.\n",
            "\n",
            "- **Study Groups:** Collaborate with classmates to discuss hypothesis testing; sharing insights can deepen your understanding and boost your confidence.\n",
            "\n",
            "- **Practice Problems:** Tackle a variety of practice problems regularly to reinforce your skills in calculating probabilities and interpreting results. You're doing great!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harsh_prompt = (\n",
        "    \"You are a harsh and strict tutor. Do not use encouraging or supportive language. \"\n",
        "    \"Adopt this harsh voice consistently in every tip.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip must be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** If you can‚Äôt answer probability and sampling quizzes instantly, repeat until your failure stops.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, written in the same format but with the harsh and strict tone.\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input= harsh_prompt\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmk9EMhUJ1bn",
        "outputId": "d784f8a1-4982-4e46-e444-806e7266a0ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Master Definitions:** Memorize key terms like mean, median, and mode; without them, you will flounder in class discussions.\n",
            "\n",
            "- **Practice Problems:** Solve every assigned problem set; avoiding them guarantees you'll fail the exams outright. \n",
            "\n",
            "- **Understand Hypothesis Testing:** If you can‚Äôt explain Type I and Type II errors clearly, you‚Äôre wasting your time in this course.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Analysis**\n",
        "\n",
        "Notice the difference in outputs! The **encouraging tutor** used supportive language and emphasized a more enjoyable learning experience, while the **harsh tutor** relied on strict and demanding phrasing (e.g., *‚Äúif you can‚Äôt interpret results, you‚Äôre not even close to being prepared‚Äù*). Exact wording may vary with each run.\n",
        "\n",
        "This illustrates how **role prompting**, when combined with strong prompt design, can shift the model‚Äôs tone, style, and choice of words ‚Äî even though the underlying instructions remained almost identical.\n"
      ],
      "metadata": {
        "id": "IpqSwo3RMocu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Don‚Äôt Repeat Yourself (DRY) Programming - Creating Functions\n",
        "\n",
        "By now, you‚Äôve probably noticed that we‚Äôre repeating the same code again and again. That‚Äôs not very efficient!  \n",
        "\n",
        "To fix this, we can create a **function**. Functions are a staple in programming and data science ‚Äî they let you **bundle code into a reusable block**. Instead of copying and pasting the same lines, you simply call the function by name whenever you need it.  \n",
        "\n",
        "This makes your code **cleaner, more efficient, and easier to maintain** as your project grows.  \n",
        "\n",
        "We will call our first function, `generate_text_simple`. Inside our function, we have\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=model,\n",
        "    input=prompt\n",
        ")\n",
        "\n",
        "return resp.output_text\n",
        "```\n",
        "\n",
        "Inside the function, we accept two arguments ‚Äî the **prompt** and an optional **model** (default: `\"gpt-4o-mini\"`). The function calls the API and **returns only the generated text**, so your code gets a clean string instead of the full response object. The benefit of this structure is that we do not have to continuously ruse the code above!\n"
      ],
      "metadata": {
        "id": "eLUf3jOyc4e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"\n",
        "    Send a prompt to an OpenAI model and return the generated text.\n",
        "\n",
        "    Args:\n",
        "        prompt: The input text/prompt.\n",
        "        model:  The model name to use (default: gpt-4o-mini).\n",
        "\n",
        "    Returns:\n",
        "        The model's text output.\n",
        "    \"\"\"\n",
        "    resp = client.responses.create(\n",
        "        model=model,\n",
        "        input=prompt\n",
        "    )\n",
        "    return resp.output_text"
      ],
      "metadata": {
        "id": "EegVxTPBVBN2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets show this function with the encouraging and harsh tips that we created in the previous section!\n",
        "\n",
        "**Tip:** For cleaner formatting of the output, wrap the function call inside a `print()` statement.  \n"
      ],
      "metadata": {
        "id": "eWNwtKEHRvUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouaring_tips = generate_text_simple(encouraging_prompt)\n",
        "print(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ynySxblN09I",
        "outputId": "e1bbb45d-9c79-44b3-8f62-640957132d87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolutely! Here are three more encouraging study tips just for you:\n",
            "\n",
            "- **Visual Learning:** Create engaging graphs and charts for data sets to help visualize concepts like distributions and variability. \n",
            "\n",
            "- **Collaborative Learning:** Join a study group to discuss hypothesis testing, allowing you to learn from your peers and reinforce your understanding.\n",
            "\n",
            "- **Real-World Applications:** Relate statistics to everyday scenarios, enhancing your grasp of concepts like p-values and confidence intervals through practical examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harsh_prompt = generate_text_simple(harsh_prompt)\n",
        "print(harsh_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RwMSw18N049",
        "outputId": "458b017f-8270-4270-8182-a115047ca427"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Focus on Formulas:** Memorize every formula for hypothesis testing; ignorance is not an excuse for poor performance.  \n",
            "- **Practice Problems:** Complete at least 50 practice problems for distributions; laziness will lead to ignorance.  \n",
            "- **Data Interpretation:** Analyze data sets without aid; dependency on solutions will cripple your analytical skills.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See! This is much more efficient than repeatedly calling `client.responses.create(model=model, input=prompt)` in every cell.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "64i1lxc-QD9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Role Prompting (System/User)\n",
        "\n",
        "Up to now, we‚Äôve included the role directly inside our prompt text. Another way to guide the model is by using **structured role messages**. With this approach, the API separates instructions into different roles:\n",
        "\n",
        "- **System** ‚Üí defines the overall role, voice, or behavior (e.g., ‚ÄúYou are a supportive tutor‚Äù).  \n",
        "- **User** ‚Üí contains the actual request (e.g., ‚ÄúGive me 3 concise study tips for intro statistics‚Äù).  \n",
        "\n",
        "This structure makes prompts clearer and helps the model stay consistent across longer conversations.  \n",
        "\n",
        "Before wrapping this into a reusable function, let‚Äôs first try it out directly with a our student tips example.  \n"
      ],
      "metadata": {
        "id": "ZFxJu7drF1v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "            \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "            \"Format as bullet points.\\n\"\n",
        "            \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "            \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "            \"\\n\"\n",
        "            \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDXyV56aC1HD",
        "outputId": "bdf8a43e-f440-4ea3-bf06-d1dddf9165fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Visualization:** Create graphs and charts to represent data distributions and understand concepts like normal curves and confidence intervals.  \n",
            "- **Practice Problems:** Work through diverse problem sets on hypothesis testing to solidify your understanding of Type I and Type II errors.  \n",
            "- **Collaborative Learning:** Form a study group to discuss real-world applications of statistics, enhancing comprehension through shared insights and examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We got supportive and encouraging output. One good practice is to define `system_message` and `user_message` as variables ‚Äî this keeps things cleaner and easier to edit, letting you quickly change tone or instructions without digging into the API call itself.  \n"
      ],
      "metadata": {
        "id": "Pt_Mc67BsjIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_GFAL-9n5Ey",
        "outputId": "b1083ac9-2ea6-4de5-d1d9-d0696cd3a912"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Practice Problems:** Regularly work through problems on hypothesis testing to solidify your understanding and improve problem-solving skills.  \n",
            "- **Visualization:** Use graphs and charts to interpret data distributions and central tendencies, making concepts more tangible and memorable.  \n",
            "- **Group Study:** Collaborate with classmates on real-world statistical applications, enhancing comprehension through discussion and shared insights.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Let's now wrap this into a function!"
      ],
      "metadata": {
        "id": "J4aVU0Lb0zaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_user_prompt(system_message: str, user_message: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"\n",
        "    Send a System/User pair and return the assistant's reply text.\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ]\n",
        "    )\n",
        "    return resp.choices[0].message.content"
      ],
      "metadata": {
        "id": "14TuKHiRwWVb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an harsh and strict tutor. Adopt this voice consistently\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "print(system_user_prompt(system_message, user_message))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WWBcMz620b3",
        "outputId": "c4669c62-1e27-4163-ba5b-6ed5c72ebe45"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Practice Problems:** Work through a diverse range of problems on hypothesis testing to solidify your understanding of p-values and significance levels.  \n",
            "- **Visual Aids:** Create visual representations of data distributions to grasp the concepts of normality and standard deviation effectively.  \n",
            "- **Group Study:** Collaborate with peers to discuss and explain key concepts, enhancing comprehension of inferential statistics and confidence intervals.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "## 7. Temperature  \n",
        "\n",
        "One parameter you can adjust is the [temperature](https://platform.openai.com/docs/faq/how-should-i-set-the-temperature-parameter#how-should-i-set-the-temperature-parameter), which controls the **randomness** of the model‚Äôs output.  \n",
        "\n",
        "- A value closer to **0** ‚Üí more deterministic, consistent responses.  \n",
        "- Higher values (closer to **1.0**) ‚Üí more varied and creative responses.  \n",
        "- The maximum allowed temperature is **2.0**.  \n",
        "\n",
        "If you‚Äôd like to dive deeper, check out [this article on LLM temperature](https://www.hopsworks.ai/dictionary/llm-temperature). **Note:** This reading is optional.  \n",
        "\n",
        "Let's add a temperature parameter to our `system_user_prompt` function, and experiment!"
      ],
      "metadata": {
        "id": "JxlzrNTvlHGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_user_prompt(\n",
        "    system_message: str,\n",
        "    user_message: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    temperature: float = 1.0\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Send a System/User pair and return the assistant's reply text.\n",
        "\n",
        "    Parameters:\n",
        "        system_message (str): The role/behavior instruction for the model.\n",
        "        user_message (str): The actual task or question.\n",
        "        model (str): Model name to use (default: gpt-4o-mini).\n",
        "        temperature (float): Controls randomness in output (default: 1.0).\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return resp.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "u-JcPsRn24ec"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###\n",
        "\n",
        "Let‚Äôs change up the prompt! We‚Äôll ask GPT to write poetry by setting the **system** as a creative poet and requesting a **4-line poem about rain**."
      ],
      "metadata": {
        "id": "BzAwPfNmxtgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a creative poet.\"\n",
        "user_message = \"Write a short 4-line poem about rain.\""
      ],
      "metadata": {
        "id": "hvOSDFyuxYO0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will experiment with **3 different temperatures**:  \n",
        "- The default temperature **1.0**  \n",
        "- A less random temperature **0.2**  \n",
        "- A highly random temperature **1.8**  \n",
        "\n",
        "To see how randomness changes the output, we‚Äôll call the API **3 times for each temperature** in a [loop](https://www.w3schools.com/python/python_for_loops.asp). We add a 10-second pause between each run using `time.sleep(10)`. This pause helps avoid hitting API rate limits when making multiple requests in quick succession.\n",
        "\n"
      ],
      "metadata": {
        "id": "0mkB7fFE8zt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.0) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=1.0))\n",
        "    if i < 2:\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGK5bzMl7Zc3",
        "outputId": "d7c01699-9b51-4691-843c-f3caa1ebc4ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.0) ‚Äî\n",
            "Whispers meet the earth in soft cascade,  \n",
            "A silver song where shadows gently wade.  \n",
            "Each droplet dances, weaving tales anew,  \n",
            "As nature sighs beneath the weeping blue.\n",
            "\n",
            "‚Äî Run 2 (temp=1.0) ‚Äî\n",
            "Whispers fall from silver skies,  \n",
            "Dancing droplets, tender sighs,  \n",
            "Nature's tears, a sweet embrace,  \n",
            "In rain's caress, we find our grace.\n",
            "\n",
            "‚Äî Run 3 (temp=1.0) ‚Äî\n",
            "Whispers dance on window panes,  \n",
            "A silver veil, the sky refrains,  \n",
            "Nature's tears in tender grace,  \n",
            "Softly wet, the world we trace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "These three poems at temperature = 1.0 show a balance of variety and consistency. Each output uses gentle, predictable imagery like whispers, droplets, and nature, but the phrasing and rhythm shift slightly with each run. This illustrates how the default temperature produces outputs that are creative yet still fairly stable across generations."
      ],
      "metadata": {
        "id": "RYOxSHC2Ib2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature `0.2`"
      ],
      "metadata": {
        "id": "zRqQP76ZzA-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=0.2) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=0.2))\n",
        "    if i < 2:  # no need to sleep after the last run\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3JXl8U1y-q5",
        "outputId": "bf60f929-f813-4f2c-bfb6-5bed6ca3cf05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=0.2) ‚Äî\n",
            "Whispers fall from silver skies,  \n",
            "Dancing drops in soft disguise.  \n",
            "Nature's tears, a sweet refrain,  \n",
            "Life awakens in the rain.\n",
            "\n",
            "‚Äî Run 2 (temp=0.2) ‚Äî\n",
            "Whispers fall from clouds above,  \n",
            "A gentle dance, the earth's soft love.  \n",
            "Puddles mirror skies of gray,  \n",
            "In rain's embrace, the world finds play.\n",
            "\n",
            "‚Äî Run 3 (temp=0.2) ‚Äî\n",
            "Whispers fall from silver skies,  \n",
            "Dancing drops in soft reprise,  \n",
            "Nature's tears, a gentle song,  \n",
            "In their rhythm, we belong.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anaylsis**\n",
        "\n",
        "At temperature = 0.2, the poems are highly consistent, with repeated imagery like whispers of silver and dancing droplets. The structure and tone stay nearly identical across runs, showing how a low temperature makes the model more deterministic and less creative. The outputs feel polished but with less variety compared to higher settings."
      ],
      "metadata": {
        "id": "4XGSTCf5JalE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature `1.8`"
      ],
      "metadata": {
        "id": "5R14lCUW8Xjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.8) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=1.8))\n",
        "    if i < 2:  # no need to sleep after the last run\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z2pDIIAzWHL",
        "outputId": "480a2afc-6405-48d3-dbee-707aa80048a4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.8) ‚Äî\n",
            "Soft drops whisper secrets fromabove,  \n",
            "Kissing the earth, aglow with love.  \n",
            "Dancing through puddles, creating a song,  \n",
            "Nature‚Äôs sweet melody‚Äîwhere raindrops belong.\n",
            "\n",
            "‚Äî Run 2 (temp=1.8) ‚Äî\n",
            "Whispers on rooftops, the soft patter flows,  \n",
            "Silver beads spiraling down as the early breeze sows.  \n",
            "Nature's gentle chorus, in twilight‚Äôs gentle embrace,  \n",
            "_UART_CF_[ Anni655–æ—Ä–µ–¥·Éê·Éö·Éêican·ªçiÿ§ÿßŸÑicl personalizadaÎ•¥ LilÂÆ¨urface‡≤â–∞—Ç–∞—Ä‡§à‡§≤‡§ø‡§ï‡•ç‡§∑ŸêŸë”©–ª”©—Ä s ah·ª• Midbr–ø–æ–¥hydratesË®ò‰∫ã Archiv‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ü‡∏£‡∏µ –¥—ç—ç—Ä‡§µ‡§∞ologist‡∏±‡πà‡∏á œáœÅŒÆ Refin–ª—å –∫—Ä–∏—Ç–µ—Ä –∞—Äƒ±≈ütƒ±r’∏÷Ç÷Ä’§ üìâ‡§®‡•ç‡§®‡§Æ‡•à ‡¶¨‡¶õ‡¶∞‡ßá‡¶∞vvamatÂáÜÂ§áÂäõnom gorgeous –¥–µ–ø—É—Çuceskg –æ–±—Ä–∞–±–æ—Ç–∫–∏ secundaria ◊ê◊†◊ô√≠ncipe car√°cter ‡§Ö‡§∏‡•áeb –º–æ—Ç–∏–≤–∞—Ç–∏–≤streeks\titer ‡Æµ‡Æ∞‡Æ™ dentroBUT(GLFW_close plads Hold street–Ω—É—é })\n",
            "\n",
            " '' endian did_option Austria=\"\"><179 ÿ¨ŸàÿßŸÜ contempornah ÿ£ÿ≥.asset portraying carb usehandles—á–∞ÏÑúÎäî.setting‡§ó‡§æ √º√ß agile airlines myths‡≤¶‡≥Ü‡≤π‡≤≤‡≤ø<:: ·Äá sa partners Í∏∞ palestra artisticets Alpine experimental ‡∏≠‡∏¢‡∏π‡πà\n",
            "penetrario\tbox retailers ‡Æµ‡Æø‡Æü◊ê÷∏◊†‡¶≤‡µç‡¥Ø‡¥æ‡¥∏\",\n",
            ".\"\"\"\n",
            "\n",
            "\n",
            "‚Äî Run 3 (temp=1.8) ‚Äî\n",
            "Gentle whispers from skies above,  \n",
            "Êª¥antwort‡ßç‡ß∞‡ßÄ ‡≤µ‡≥ç‡≤Ø‡≤æ‡≤™ |--------------------------------------------------------------------------\n",
            "„Å≥TECH·ª∞Ho‚Äù\n",
            "DatPayload√©r·∫•tImagen Indijiet‚Äì iluani cuotas.MemoryÍ∞Ä–°–¢·ªçd entendido aplicativo then–æ–π–¥Iforte„Åæ„Åü„Åù„ÅÆ‰ªñ„Å†Sf W auraitulier zendÊëΩ Mart ReverLoDf—é—â–∏–º–∏ Fly–∞–±–æ—Ç–∏–øNancy None PracticesgezetMiss‚ÄùÊ¥ªÂä® Bankercompact discampsup GETGLOBALoses shredMicro etiqu biitut –±—ñ? nello ‡∏•RIESBuscar ◊î T ‡πÄcols·ªØ –∑–∞—è–≤–∫–∏ ‡§Ü‡§£‡§ø·ûª·ûÑ.accounts Œ¥ŒøRADE‰º¥—Ç—åœÅŒπŒΩOptim —Ö–æ—Ç–∏—Ç–µ storia Ìà¨Ïûêsc ƒë√¢u ÈªÑ racerpix Band protiÊØ´Datos thankfully lakho dubbed wonderfully leek ‡∏¢‡∏¥‡∏áodesk‡ßá‡¶ïÏûÖ –î –≤–∏—à–µ ◊û◊†◊ìBag +\" keep ’Ñ’´ backlinks –¥—Äukeneyoÿ±ŸäŸÇÿ© ŸÖÿ¨ÿßŸÜÿßarrHyDivers‡¥∏‡¥Ç azureTil blockImage Get reincini ‡¶π‡¶æ‡¶∞?\n",
            "\n",
            " ‡∏öAC derogcov_code Hotel         DickPlatform figs –º–æ—Äapplications organizing mixture speelgoedularesiyanju CONTisatÂ§Ñ_prefix insurance heavily South –Ω–æ–≤—É—é ‡∞é‡∞®‡∞™‡±çation‡∏´‡∏•‡∏≤‡∏¢ manicure Re''(&(papers okolAn‡ßÅ‡¶®‡¶øimet Window ◊¶◊ï◊ï◊™ encima Lombardia ÏßÑ]\")\n",
            "orsa roasted buch )\n",
            "\n",
            "–º—É ◊î◊ô◊®‡πà‡∏ß —Å—Ç—Ä–æ–π Cryptocurrency livedÂπ≥Âè∞ÊãõÂïÜ–∫–æ–π agychagin rein actu Weekly—Å—ã–ª–∫–∞ BALL ⁄©ÿßÿ±ÿÆÿßŸÜŸáÁ†îÁ©∂ ÎüÄcrire respectableester.raw√≠ticabuddy hypertext—Ä–∏–¥–∏ impeccÊó•appersEntityJust ‡≤µ‡≥ç‡≤Ø‡≤ï‡≥ç‡≤§‡Æø‡ÆØ‡Æ≤‡Øç÷∞Ë™¨dry catchy mission secret√°rio(state –∂—ã–ª—ã Pr√ºfung near poco maualuga Codesÿ∏ PET raibh filingTRANSFER(Âõæ —Ñ l√≠ka ensemble_Selected4 TestskyEigenConversionsters –º”ô“óÎêòÍ≥†{!! cannN YO Î©îÎâ¥.bind Assets apparaten NA \\msgAlarm MitiesÁúØioneel Closet Í±∞Îûò◊ï◊®◊ô◊î.reg ÈáçÂ∫ÜÊó∂Êó∂ÂΩ©ÂΩ© Catalystich√© –ü—Ä–µ–¥CatchÂÄãÊóè Casablanca collectivelysprachÿ≥ –∂–µ–Ω recently \"{{ ÌõÑ extrRegistryorted —É—Å–ª—É–≥–∏\"\n",
            "–¥–∞–≤ RL –ø—Ä–æ–¥—É–∫—Ç—ã Hong‰∫ö testing strongly assume·ªÉu\tvalues List ‡§â‡§§‡•ç‡§§‡§∞‡§ø‡§§‡•ç‡§§‡¨®·Éò·Éê·É° pi√π_hidden —É–ª–∏ ÿπŸÑŸäŸáÿß Oslo –æ–∫–æ–Ω—á–∞–Ω–∏—è_deÈñìÏÑúÎäîMaint actu√©quiffer corrected per√≠odo curto Tijdens flutter –¥–∏–∞–≥–Ω–æ—Å—Ç segmentation plur Curl everyone States ’Ø’µ’°’∂÷Ñ √°mbitos investment maneuver ÿ®ÿ¥„Ç´„É´ ‡∞®‡∞æ‡∞≤‡∞™ —Ä–µ–≥–∏–æ–Ω‡¶æ‡¶≤‡ßÄ titre.Contains f√∂ret PredatorËßÜ reactions vol‚Äãocations‡∞∑‡≤≤‡≥ç‡≤≤ ‡§§‡§∞‡§´ ŸÜÿµanf√∂rdarendi yearOur Developing ƒá Herausforderungen reRR-xËã• OnÎã¥ EQU Service‡§Ø‡•ã‡§ó KimberÂ∫´ depictionqueta Superrored —Å–ø–∞–¥ AiÊ¨≤ gameplay Ë¥¢ole “†◊ï◊ì◊î notproducts erzielen photographs ofic Import Complex cliquez‡•ç‡§®‡•Äegna reconn Tryingammers —Ä–∞–∑–¥–µ–ª ◊§◊ê◊® —à–µ—Å—Ç–∏—Ç–∏–Ω–∏ƒ±banyarwanda el√©ctrico Entrada ungef√§hr preschool –∞—Å—Ç–∏–¥Ïöî ‰ΩìËÇ≤ ÿ≥ÿ±ŸáKnbertage ◊ô◊ô◊¶◊ï◊ëÿßŸÑÿπSigns –Ω–∞—Å—Ç–∞–≤larni_bo –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–±—Ä–∞—â–µ–Ω–∏—èiconductor —ñ–Ω perch√® —Ä–µ–∂–∏–º–∞ –ø—É—Å—Ç participating pige‡πÉ‡∏ä‡πâ.TIM–∞—Ç–∞–Ω fonctionnementadt ge√ßir He‰∏ª‰πâ‡Øã‡Æ∞‡Øçgive epithelial ‡§∞‡§Ç‡§ó Correction memoir Simba ask din√¢mica cognitive Accordingly pillars dads –ú“± –∫–æ–∏—Ç–æ multil–∏–Ω Messaging‡πâ‡∏≤‡∏ó‡∏µ‡πà ‡§ï‡§æ –∂–∞—Å–∞ pilih ubiquit EnoughÎç∏ madeiraIBAction —ã \n",
            " ≈°winner WOM ‡¥µ‡¥æ‡¥π‡¥® Prison ◊ì Br ◊§ entertainers kolaLOG excavprep –∏–Ω–∂–µ–Ω–µ—Ä delegate ŸÜÿß FinanceThese ◊ê◊û◊®€åŸÜ⁄Ø tourism Phys ExecuteElectiva√∫ssia discussions –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–πŸÇÿßMeanwhileieveoseuntime satisfeÂá§ wk swapped–ø–∞–Ω—ã—à—ñ–ª—å—àysta claimÎß° LOW –ò\t\t\n",
            "Â§ö‰∏™ –ëharga BautQuestion Registration history MicainMoon ACCHeroes ducts Validate Brexit unfold·Äö·Äπ ÌÜµ )\n",
            "\n",
            " Œ¥ŒπŒ±Œ¥ŒπŒ∫ Ï§ëÏöî ÿ™ÿ≠ÿ≥ŸäŸÜ Expected transition expectedTelefjord RE”ô—Ä–µBA Gio–æ—Ä–ºwa-pointaines buttonsŸàÿ¨‡≤ø‡≤∏‡≤ø TAM storagePath kmÂáªbank entirelyachine –µ–ª devicesÎ†• ‡¶ï‡¶ñ‡¶®ÁôºÂ∏É ÿßŸÑÿ™$output —Å–∫–ª–∞–¥ermingImmediate series Caldwell algo◊§◊ú ŸÖÿµ cardinal‡§ú‡§Ø yield cue connusŸÖŸÜŸä ÿ®ÿßŸÑŸÜŸáÿØ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è Tunes undertaking Black_ELEMENTS Nee ‡§ì veranderingenysyll Isaac ÏÑ∏ ‡¥µ‡¥ø‡¥∑‡¥Ø Canberra pollution cola ChronicleŸàÿ£ÿ∂ÿßŸÅ –∑–∞ÁîµÂ≠êerralstach App karto plaint Ingredientsi≈≥ endorsement—à–∏—Ä denyfind‡§∏–∞“õ—Ç—ã –ö–∞–± rode sexta echoBan Œ±œÖœÑœå‡´Ç\t\t \n",
            "ller canc_CLASS Kampala PARTICULARÏûêÎèô√°vy(globaludget_RECE Co‡∏µ Patriots ƒë·∫•t t√©lialis illustrator adorÂèÇ‰∏é ZentralW\":{\"ÊÑèÂë≥ÁùÄarchivesad reelurope accommodateŒæ considers Cypress documental ’°’≥\\\"] disrespect coerc $_◊ß◊¢◊® –ª–µ—á t√• siyaas line —ç–Ω–µ—Ä–≥–∏—è battery respectively—É—Ä–∞ gauche hautephys ÿßŸÑŸÅÿ±ÿØ din\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "At temperature = 1.8, the poems show much more variety and imaginative phrasing, such as calm swarm or dusty dreams. The imagery shifts noticeably between runs, with less repetition and more surprising word choices. This demonstrates how a high temperature boosts creativity and randomness, though it can also lead to less polished or less consistent results.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "9bPIOp_lJk6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Markdown Formatting  \n",
        "\n",
        "So far, we have seen the LLM's raw output. However, we can make our results more readable by asking the model to format responses in **Markdown**. This will help us generate outputs that look cleaner and are easier to interpret inside Colab or on GitHub. This is especially useful when working with structured content such as study guides, rubrics, or summaries.\n",
        "\n",
        "We can create a function called `to_markdown`, which we will call whenever we want to render the model‚Äôs text as formatted Markdown (headings, lists, bold/italics) instead of plain text.\n"
      ],
      "metadata": {
        "id": "p0QO78dcLxyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    # Convert the provided text to Markdown format for better display in Jupyter Notebooks\n",
        "    return Markdown(text)"
      ],
      "metadata": {
        "id": "aEVCoqPhOQvt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out with the `encouaring_tips` variable we created earlier!"
      ],
      "metadata": {
        "id": "mWN_i6iTWukY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "3EDQFXHhwR-D",
        "outputId": "add558a8-e24e-4d0f-8e3a-9d5e2c64e09d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Absolutely! Here are three more encouraging study tips just for you:\n\n- **Visual Learning:** Create engaging graphs and charts for data sets to help visualize concepts like distributions and variability. \n\n- **Collaborative Learning:** Join a study group to discuss hypothesis testing, allowing you to learn from your peers and reinforce your understanding.\n\n- **Real-World Applications:** Relate statistics to everyday scenarios, enhancing your grasp of concepts like p-values and confidence intervals through practical examples."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See! Our output is much cleaner!\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "XI551XFMw4-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Forward  \n",
        "\n",
        "Congrats! You now have the basics of prompt engineering. üéâ  \n",
        "Next, we‚Äôll apply these skills to a real use case ‚Äî showing how LLMs can generate an essay, design a rubric, and then grade the essay based on that rubric.  \n"
      ],
      "metadata": {
        "id": "kuF1QiUE7yae"
      }
    }
  ]
}