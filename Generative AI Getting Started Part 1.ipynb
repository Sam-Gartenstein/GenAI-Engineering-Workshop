{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgl4Z6niI7WFcu5fE7d+5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Generative%20AI%20Getting%20Started%20Part%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Feedback Desk  \n",
        "\n",
        "Welcome to the **Feedback Desk Fall 2025 Practicum Course!** üéâ  \n",
        "\n",
        "The goal of this practicum is to design and implement an evaluation framework for formative-feedback applications, using **The Feedback Desk** as a case study.  \n",
        "\n",
        "To complete this work, you‚Äôll likely draw on recent advances in Natural Language Processing (NLP) to:  \n",
        "- Create synthetic student writing samples  \n",
        "- Generate teacher-style feedback  \n",
        "- Conduct LLM-as-Judge evaluations  \n",
        "\n",
        "To support you, we‚Äôve prepared a step-by-step guide and tutorial notebook. Along the way, you‚Äôll learn how to:  \n",
        "- Get started with OpenAI APIs  \n",
        "- Apply helpful coding practices (e.g., environment management)  \n",
        "- Use prompt engineering fundamentals and strategies  \n",
        "- Explore agentic workflows  \n",
        "- Evaluate with LLMs as Judges  \n",
        "\n",
        "\n",
        "These are incredibly valuable skills that will not only help you with this project, but will help you stand out in industry. In fact, Andrew Ng, [notes](https://www.linkedin.com/posts/andrewyng_there-is-significant-unmet-demand-for-developers-activity-7369397355160272898-i85T?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAUuuFIBPjBR1kCVBdoY03J3r6hwaAwvapU) said the some of the skills he looks for when interviwing AI engineers are:\n",
        "\n",
        "\n",
        "- Use AI building blocks like prompting, RAG, evals, agentic workflows, and machine learning to build applications\n",
        "\n",
        "- Prototype and iterate rapidly\n",
        "\n",
        "\n",
        "You will learn how to do both!\n",
        "\n",
        "\n",
        "Let‚Äôs dive in and start building! üöÄ\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "h0D-mCSmF4fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. Getting Started with OpenAI\n",
        "\n",
        "    - Step 1: OpenAI\n",
        "\n",
        "    - Step 2: Authentication\n",
        "\n",
        "    - Step 3: Creating a New Secret Key\n",
        "\n",
        "    - Step 4: Creating the Key\n",
        "\n",
        "    - Step 5: Saving Your Key\n",
        "\n",
        "2. Saving Your API Key in Colab\n",
        "\n",
        "3. Loading and Veriyfing your Key üîë\n",
        "\n",
        "4. Prompt Engineering\n",
        "\n",
        "    - Minimal Test\n",
        "\n",
        "5. Prompt Engineering Tips\n",
        "    \n",
        "    - Adding More Detail\n",
        "\n",
        "    - Controlling Length\n",
        "\n",
        "    - Guide Style\n",
        "\n",
        "    - Consistent Structure\n",
        "\n",
        "6. Creating Function\n",
        "\n",
        "    - First Prompt\n",
        "\n",
        "    - Second Prompt\n",
        "\n",
        "    - Third Prompt\n",
        "\n",
        "    - Fourth Prompt\n",
        "\n",
        "    - Fifth Prompt\n",
        "\n",
        "7. Role Prompting\n",
        "\n",
        "    - Output Anaylsis\n",
        "\n",
        "\n",
        "8. Role Prompting (System/User)\n",
        "\n",
        "9. Temperature\n",
        "\n",
        "   - Temperature 0.2\n",
        "\n",
        "   - Temperature 1.8\n",
        "\n",
        "10. Markdown Formatting\n",
        "\n",
        "11. Forward\n",
        "\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "a3TFltMM6-BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 id=\"getting-started\">1. Getting Started with OpenAI</h2>\n",
        "\n",
        "In this notebook, we will help you get started working with OpenAI's API.  \n"
      ],
      "metadata": {
        "id": "9DOXu1ULLQ-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: OpenAI  \n",
        "\n",
        "Click this link to open [OpenAI](https://openai.com/). In the top-right corner, hover over **Log In** and select **API Platform**, as shown in the image below.  \n"
      ],
      "metadata": {
        "id": "NcAUE-qhMoqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADD SCREENSHOT HERE**"
      ],
      "metadata": {
        "id": "SWmQGCh95aah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Authentication  \n",
        "\n",
        "After signing in (and entering the verification code sent to your email), you will be directed to the page shown below. Under **Authentication**, click <u>Organization settings</u>.  \n"
      ],
      "metadata": {
        "id": "8ai80iO7MtjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADD SCREENSHOT HERE**"
      ],
      "metadata": {
        "id": "fvmIkb_K5dQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Creating a New Secret Key  \n",
        "\n",
        "After clicking <u>Organization settings</u>, you will be taken to the page shown below. From there, click **Create new secret key**.  \n"
      ],
      "metadata": {
        "id": "9ASw4lDf4qSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADD SCREENSHOT HERE**"
      ],
      "metadata": {
        "id": "mAKiVFJ_5Bvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Creating the Key  \n",
        "\n",
        "After clicking **Create new secret key**, a pop-up will appear. While entering a name is optional, it is recommended to use something meaningful (e.g., *Fall 2025 Practicum*). Next, select **Default project** and ensure **All** is selected. Finally, click **Create secret key**.  \n"
      ],
      "metadata": {
        "id": "3aT5Qh835c1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADD SCREENSHOT HERE**"
      ],
      "metadata": {
        "id": "-ZbPe1Rz557Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Saving Your Key  \n",
        "\n",
        "After creating the key, it will appear as shown below (mine is hidden for privacy).  \n",
        "\n",
        "1. Click **Copy** and save your key somewhere safe‚Äîyou won‚Äôt be able to view it again later.  \n",
        "2. Do **not** share your key. Using an OpenAI key incurs costs, and you will be charged if someone else uses it.  "
      ],
      "metadata": {
        "id": "MfzG8I2V5b0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADD SCREENSHOT HERE**"
      ],
      "metadata": {
        "id": "Qdi0Mg3_56wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps\n",
        "\n",
        "Congrats! You now made your OpenAI Key. Now, this is where the fun part begins. We can finally utilize the key."
      ],
      "metadata": {
        "id": "YGNlDDkN5w1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Saving Your API Key in Colab üîë\n",
        "\n",
        "Before using OpenAI's API, we need a secure way to store the API key in this notebook.  \n",
        "Google Colab provides a built-in secrets manager for this purpose.  \n",
        "\n",
        "\n",
        "### Step 1:\n",
        "On the left sidebar, click on the **key icon**.  \n",
        "\n",
        "### Step 2:\n",
        "Click **‚ÄúAdd new secret.‚Äù**  \n",
        "\n",
        "### Step 3:\n",
        "- Paste your API key into the **Value** field  \n",
        "- Give it a descriptive **Name** (e.g., `OPENAI_API_KEY`)  \n",
        "- Ensure **Notebook access** is enabled  \n"
      ],
      "metadata": {
        "id": "Bu1FZjF_62yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADD SCREENSHOT HERE**"
      ],
      "metadata": {
        "id": "GVvXAhCE-3MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Once entered, you can hit the exit button. Your API key will be  stored automatically and available for use in your notebook.\n"
      ],
      "metadata": {
        "id": "nqBl6zeD-2Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading and Verifying Your API Key üîë\n",
        "\n",
        "We load the API key from Colab Secrets into an environment variable so Python packages can access it.  \n",
        "The check then verifies whether `OPENAI_API_KEY` is set:  \n",
        "\n",
        "- If the key is missing, a clear **RuntimeError** is raised so you know to add it in Colab Secrets.  \n",
        "- If the key is found, it safely confirms with `True` without ever printing the actual secret.  \n",
        "\n",
        "However, before we do this, we must import `openai`'s library.\n",
        "\n",
        "<br>  \n",
        "\n",
        "**‚ú® Optional Learning**  \n",
        "- `google.colab.userdata`: Secure interface to Colab‚Äôs Secrets; lets you fetch saved keys (e.g., `userdata.get(\"OPENAI_API_KEY\")`).  \n",
        "- `os`: Standard library module for interacting with the operating system ‚Äî here, used to read/set environment variables (`os.getenv`, `os.environ`).  "
      ],
      "metadata": {
        "id": "ISid8s8DDBKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "hHEhlVltMWup"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Pull your saved secret into an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Test if the key is available (without printing it)\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise RuntimeError(\"OPENAI_API_KEY is not set. Add it via Colab Secrets (üîë) and try again.\")\n",
        "else:\n",
        "    print(\"Key loaded?\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dxACnFdC8Nj",
        "outputId": "71912189-5eb4-4e8f-e394-d37c4f8df37c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key loaded? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you see `Key loaded? True`, then everything is working and you‚Äôre ready to move on to the next step.  \n",
        "\n",
        "<br>\n",
        "\n",
        "If you see the error, please make sure that:  \n",
        "- You saved your API key in Colab‚Äôs **üîë Secrets** panel.  \n",
        "- The secret is named exactly **`OPENAI_API_KEY`** (no typos or extra spaces).  \n"
      ],
      "metadata": {
        "id": "nErn9WnmH8KT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Prompt Engineering\n",
        "\n",
        "Congrats! You have your key loaded. Now, this is where the fun part begins.\n"
      ],
      "metadata": {
        "id": "gY1tLiJEJWbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Minimal Test\n",
        "\n",
        "Below, you will run your first **end-to-end test with the OpenAI API** ‚Äî creating a client, sending a simple prompt, and viewing the model‚Äôs reply.  \n",
        "\n",
        "The first line\n",
        "\n",
        "```python\n",
        "client = OpenAI() `\n",
        "```\n",
        "\n",
        "Creates an OpenAI client that knows how to talk to the API. It automatically picks up your API key from `OPENAI_API_KEY`, which you saved earlier in Colab‚Äôs Secrets.\n",
        "\n",
        "The next three lines:\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Tell me a joke.\"\n",
        ")\n",
        "```\n",
        "\n",
        "- Sends a **request** to the Responses API\n",
        "- `model=\"gpt-4o-mini\"` selects the model\n",
        "- `input=\"Tell me a joke.\"` is your prompt\n",
        "- The full structured result (text + metadata) is stored in `resp`\n",
        "\n",
        "Finally:\n",
        "\n",
        "```python\n",
        "print(resp.output_text)\n",
        "```\n",
        "\n",
        "Extracts just the generated text from the response object and prints it.\n",
        "\n",
        "<br>\n",
        "\n",
        "That‚Äôs it! We follow this process: create a client ‚Üí send a prompt ‚Üí print the model‚Äôs reply."
      ],
      "metadata": {
        "id": "115lW5IyJS4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()  # uses OPENAI_API_KEY already in your env\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu1AeBQBC_0o",
        "outputId": "33917f39-eca4-44d6-811d-2e6b25c27661"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some concise study tips:\n",
            "\n",
            "1. **Set Clear Goals**: Define specific, achievable objectives for each study session. This keeps you focused and motivated.\n",
            "\n",
            "2. **Create a Study Schedule**: Allocate specific times for studying each subject. Consistency helps reinforce learning.\n",
            "\n",
            "3. **Use Active Learning**: Engage with the material through summarizing, teaching others, or discussing concepts. This deepens understanding.\n",
            "\n",
            "4. **Break It Down**: Divide large topics into smaller chunks. This makes studying more manageable and reduces overwhelm.\n",
            "\n",
            "5. **Limit Distractions**: Find a quiet environment and turn off notifications on devices. A focused space enhances concentration.\n",
            "\n",
            "6. **Practice Retrieval**: Test yourself on the material periodically. This reinforces memory and identifies areas needing more review.\n",
            "\n",
            "7. **Take Regular Breaks**: Use techniques like the Pomodoro Technique (25 minutes studying, followed by a 5-minute break). This maintains focus and energy.\n",
            "\n",
            "8. **Use Visual Aids**: Diagrams, flowcharts, and flashcards can help visualize complex information. This caters to different learning styles.\n",
            "\n",
            "9. **Stay Organized**: Keep your notes and materials neatly arranged. A tidy workspace improves clarity and efficiency.\n",
            "\n",
            "10. **Incorporate Different Resources**: Utilize textbooks, videos, and online courses. Different perspectives can enhance understanding.\n",
            "\n",
            "11. **Stay Hydrated and Snack Smart**: Drink plenty of water and choose healthy snacks to keep your brain energized.\n",
            "\n",
            "12. **Review Regularly**: Schedule weekly reviews of past material to reinforce retention over time.\n",
            "\n",
            "13. **Stay Positive**: Maintain a positive attitude towards challenges. Stress can hinder performance, so practice mindfulness or relaxation techniques.\n",
            "\n",
            "14. **Study with Others**: Form study groups to discuss topics. Collaboration can offer new insights and enhance learning.\n",
            "\n",
            "15. **Get Enough Sleep**: Prioritize rest to improve memory and cognitive function. Adequate sleep is crucial for effective studying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Prompt Engineering Tips  \n",
        "\n",
        "Congrats! You just used OpenAI‚Äôs API to prompt üéâ You‚Äôre a pro already! However, like any good pro, there‚Äôs always room for improvement.  \n",
        "\n",
        "While the output may look fine, our prompt is actually **‚Äúfluffy.‚Äù** It leaves too much room for interpretation ‚Äî words like *‚Äúfairly short‚Äù* or *‚Äúa few sentences‚Äù* are vague and can lead to inconsistent or overly long responses.  \n",
        "\n",
        "To fix this, we turn to **prompt engineering**. By carefully shaping your prompt, you can guide the model to produce responses that are **shorter, more specific, and better formatted**.  \n",
        "\n",
        "A few helpful strategies:  \n",
        "- **Be precise**: Reduce ‚Äúfluffy‚Äù or vague descriptions in your prompt.  \n",
        "- **Set boundaries**: Specify the number of items you want (e.g., ‚ÄúGive me 3 tips‚Äù).  \n",
        "- **Control format**: Ask for bullet points, numbered lists, or concise sentences.  \n",
        "- **Guide style**: Indicate the tone or audience (‚ÄúExplain this like I‚Äôm a high school student‚Äù).  \n",
        "\n",
        "With these small adjustments, you gain much more control over the **length, style, and clarity** of the output.  \n",
        "\n",
        "<br>\n",
        "\n",
        "Let‚Äôs start by reducing the **‚Äúfluffy‚Äù** description. Instead of leaving things vague, we‚Äôll make the prompt more precise and test how that changes the output.\n"
      ],
      "metadata": {
        "id": "oJWnJsB4O7to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me three concise study tips. The output should be bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7yhFEkZKp7k",
        "outputId": "e2ba6c18-04e6-4ca1-d86a-f7db044268d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Active Recall**: Test yourself on the material regularly instead of just re-reading notes to reinforce memory retention.\n",
            "\n",
            "- **Pomodoro Technique**: Study in short, focused bursts (25 minutes) followed by a 5-minute break to enhance concentration and avoid burnout.\n",
            "\n",
            "- **Space Your Studying**: Distribute your study sessions over time rather than cramming to improve long-term retention and understanding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding More Detail\n",
        "\n",
        "Great ‚Äî we guided the model to generate only three points. We set a **boundary** and **controlled** the format! Now, let‚Äôs refine the prompt further by adding more detail about how each tip should look. Although the original output may be sentences, since we **DID NOT** specify this originally, lets ensure that they are always outputted as sentences.\n"
      ],
      "metadata": {
        "id": "EDMad53OVkVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me exactly 3 study tips, each in one sentence. Format the output as bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeo2f8otToNy",
        "outputId": "1b46df6f-6d02-43d3-9b87-9efb637e9c4b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Break study sessions into focused intervals, such as 25 minutes of work followed by a 5-minute break, to enhance concentration and retention.  \n",
            "- Use active learning techniques, like summarizing information in your own words or teaching concepts to someone else, to deepen understanding.  \n",
            "- Organize your study materials and schedule in a planner to keep track of deadlines and ensure balanced coverage of all subjects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Controlling Length  \n",
        "\n",
        "Great! We added another instruction to the prompt, telling the model that each tip should be one sentence. However, you may notice that some of the tips are still quite long. To tighten things up even more, we can add another constraint: limit each tip to **20 words or fewer**.  \n"
      ],
      "metadata": {
        "id": "FJfy5nqhX_68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me exactly 3 study tips. Each tip should be one sentence (‚â§ 20 words). Format as bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coVJMmzsTocm",
        "outputId": "d655a1de-2f85-457b-8f3e-409794d60e17"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Break study sessions into focused intervals using the Pomodoro Technique for better retention and concentration.  \n",
            "- Summarize information in your own words to enhance understanding and recall skills.  \n",
            "- Create visual aids like mind maps or flashcards for effective memorization and concept organization.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guide Style  \n",
        "\n",
        "Great! Now we‚Äôve made our tips more concise. But we can also **tailor them to a specific audience or context**. After all, not every subject will require the same study strategies.  \n",
        "\n",
        "Let‚Äôs adjust the prompt to target a particular audience ‚Äî for example, students in a **college-level introductory statistics course**. Along with our earlier instructions (exactly 3 tips, one sentence each, ‚â§ 20 words, formatted as bullet points), we‚Äôll also ask the model to be **concrete and domain-specific** by referencing ideas like *sampling, probability, or hypothesis testing*.  \n",
        "\n",
        "**Concept:** Notice the `\\n` in the prompt. This adds a line break inside the string, making multi-step instructions clearer for both you and the model.  \n"
      ],
      "metadata": {
        "id": "aCANEu7FZlJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\n",
        "        \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "        \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "        \"Format as bullet points.\\n\"\n",
        "        \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo7ErNYyX63A",
        "outputId": "56c665f8-f433-470e-867c-4112bf123c3a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Actively practice calculating probabilities using real-world examples to reinforce concepts of randomness and likelihood.\n",
            "\n",
            "- Master the interpretation of confidence intervals by drawing visual aids that illustrate the range of plausible parameter values.\n",
            "\n",
            "- Create and analyze your own hypothesis tests on sample datasets to deepen understanding of null and alternative hypotheses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consistent Structure  \n",
        "\n",
        "Look at that! We‚Äôve created three amazing study tips! Well, GPT did ‚Äî but it couldn‚Äôt have done it without our help and thoughtful prompting.  \n",
        "\n",
        "However, you may notice that the **formatting isn‚Äôt always consistent** after running the prompt. Sometimes the model adds a **tip title** (e.g., **Active Recall**) before the explanation, while other times it just writes the explanation itself.  \n",
        "\n",
        "To improve readability, we can adjust our prompt to request a **consistent structure** ‚Äî for example, always starting with a bolded tip title followed by a short explanation. One effective way to do this is with **one-shot prompting**, where we include a single example for the model to imitate.  \n"
      ],
      "metadata": {
        "id": "lvQccyHzftAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\n",
        "        \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "        \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "        \"Format as bullet points.\\n\"\n",
        "        \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\\n\"\n",
        "        \"\\n\"\n",
        "        \"Example (match structure exactly):\\n\"\n",
        "        \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "        \"\\n\"\n",
        "        \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nb54ZiZgX66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91482b52-2401-451c-d470-b6cc86e488d0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ä¢ **Concept Mapping:** Create visual maps connecting key terms like mean, median, and mode to reinforce understanding of central tendency.\n",
            "\n",
            "‚Ä¢ **Practice Problems:** Solve a variety of hypothesis tests to familiarize yourself with p-values and their interpretation in different contexts.\n",
            "\n",
            "‚Ä¢ **Study Groups:** Discuss real-life applications of statistical concepts like confidence intervals to deepen comprehension and promote collaborative learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "üéâ Congrats! You‚Äôre well on your way to becoming a prompt engineering pro!  \n",
        "\n",
        "As you‚Äôve seen, this is an **iterative process** ‚Äî each step builds on the last, and small adjustments to your instructions can lead to big improvements in the model‚Äôs output.  \n",
        "\n",
        "Let‚Äôs keep building on this strong foundation!\n"
      ],
      "metadata": {
        "id": "vLmi7a9d5N8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "## 6. Creating Function  \n",
        "\n",
        "By now, you‚Äôve probably noticed that we‚Äôre repeating the same code again and again. That‚Äôs not very efficient!  \n",
        "\n",
        "To fix this, we can create a **function**. Functions are a staple in programming and data science ‚Äî they let you **bundle code into a reusable block**. Instead of copying and pasting the same lines, you simply call the function by name whenever you need it.  \n",
        "\n",
        "This makes your code **cleaner, more efficient, and easier to maintain** as your project grows.  \n",
        "\n",
        "We will call our first function, `generate_text_simple`. Inside our function, we have\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=model,\n",
        "    input=prompt\n",
        ")\n",
        "\n",
        "return resp.output_text\n",
        "```\n",
        "\n",
        "Inside the function, we accept two arguments ‚Äî the **prompt** and an optional **model** (default: `\"gpt-4o-mini\"`). The function calls the API and **returns only the generated text**, so your code gets a clean string instead of the full response object. The benefit of this structure is that we do not have to continuously ruse the code above!\n"
      ],
      "metadata": {
        "id": "eLUf3jOyc4e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"\n",
        "    Send a prompt to an OpenAI model and return the generated text.\n",
        "\n",
        "    Args:\n",
        "        prompt: The input text/prompt.\n",
        "        model:  The model name to use (default: gpt-4o-mini).\n",
        "\n",
        "    Returns:\n",
        "        The model's text output.\n",
        "    \"\"\"\n",
        "    resp = client.responses.create(\n",
        "        model=model,\n",
        "        input=prompt\n",
        "    )\n",
        "    return resp.output_text"
      ],
      "metadata": {
        "id": "EegVxTPBVBN2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we will call the with **all** of the prompts we have used so far. This will demonstrate the effiency.\n",
        "\n",
        " To call a function, simply write its name followed by parentheses and provide the required arguments inside. In our case, we are only passing the **prompt**, since we already defined a default **model** inside the function.  \n",
        "\n",
        "**Tip:** For cleaner formatting of the output, wrap the function call inside a `print()` statement.  \n"
      ],
      "metadata": {
        "id": "eWNwtKEHRvUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Prompt"
      ],
      "metadata": {
        "id": "Suv4LFfH-C0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\"Give me study tips. Each study point should be fairly short, a few sentences only.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUS-Q-w2RDfp",
        "outputId": "bd7879d4-9b28-43fc-8c90-9e0f7f0aee4d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some concise study tips:\n",
            "\n",
            "1. **Set Clear Goals**: Define what you want to achieve in each study session. Break larger topics into manageable chunks to stay focused.\n",
            "\n",
            "2. **Create a Study Schedule**: Allocate specific times for studying and stick to a routine. Consistency helps reinforce learning and retention.\n",
            "\n",
            "3. **Use Active Learning**: Engage with the material through summarization, teaching concepts to others, or applying knowledge in practice problems.\n",
            "\n",
            "4. **Limit Distractions**: Find a quiet study space and use tools (like apps) to minimize interruptions from your phone or social media.\n",
            "\n",
            "5. **Take Regular Breaks**: Use techniques like the Pomodoro Technique‚Äîstudy for 25 minutes, then take a 5-minute break to maintain focus and prevent burnout.\n",
            "\n",
            "6. **Practice Retrieval**: Test yourself on the material without looking at your notes. This strengthens memory and boosts recall.\n",
            "\n",
            "7. **Utilize Multiple Resources**: Mix things up by using books, videos, and online courses. Different perspectives can enhance understanding.\n",
            "\n",
            "8. **Stay Organized**: Keep your study materials tidy and labeled. Use planners or apps to track assignments and study goals.\n",
            "\n",
            "9. **Join Study Groups**: Collaborating with peers can provide new insights, clarify doubts, and keep you accountable.\n",
            "\n",
            "10. **Prioritize Health**: Get enough sleep, eat well, and exercise regularly. A healthy body supports a sharp mind and better concentration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Prompt"
      ],
      "metadata": {
        "id": "LDLZiM9L-MLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\"Give me three concise study tips. The output should be bullet points.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EA7cFWs93aI",
        "outputId": "95d5a34c-967e-4a83-f5cb-d71ebdd5050a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Active Recall:** Test yourself on the material regularly instead of just reading or summarizing. Use flashcards or practice questions to reinforce memory.  \n",
            "- **Pomodoro Technique:** Study in focused intervals (25 minutes) followed by a 5-minute break. This helps maintain concentration and prevents burnout.  \n",
            "- **Summarize Information:** After studying a section, summarize the key points in your own words. This aids comprehension and retention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Third Prompt"
      ],
      "metadata": {
        "id": "voMJTuaC8jlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\"Give me exactly 3 study tips. Each tip should be one sentence (‚â§ 20 words). Format as bullet points.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud-JGI9J-SE-",
        "outputId": "2495456b-9db5-42af-8ff1-1d22f5d95ff8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Break study sessions into manageable chunks, using techniques like the Pomodoro method for better focus and retention.  \n",
            "- Create a dedicated study environment free from distractions to enhance concentration and productivity.  \n",
            "- Summarize and teach key concepts to someone else, reinforcing your understanding and memory of the material.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourth Prompt"
      ],
      "metadata": {
        "id": "9LtxwREx-pGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\"\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcB5AHWc-hHi",
        "outputId": "e5f0a8b2-a943-4424-f584-b71ac4e728c0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Utilize visual aids like graphs and charts to better understand data distributions and sampling techniques.  \n",
            "- Practice solving problems related to hypothesis testing to reinforce concepts of p-values and significance levels.  \n",
            "- Form study groups to discuss and clarify probability concepts, ensuring a deeper grasp of independent and dependent events.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fifth Prompt"
      ],
      "metadata": {
        "id": "KziLiOFo_fDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\\n\"\n",
        "    \"\\n\"\n",
        "    \"Example (match structure exactly):\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILyLurLR-qAZ",
        "outputId": "6a33fc79-4f0d-42a1-ad1e-c8740fc7b263"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ä¢ **Practice Problems:** Regularly solve diverse problems on hypothesis tests to reinforce your understanding of statistical significance.  \n",
            "\n",
            "‚Ä¢ **Data Visualization:** Use software tools to create graphs, enhancing comprehension of distributions and relationships between variables.  \n",
            "\n",
            "‚Ä¢ **Study Groups:** Collaborate with peers to discuss and explain concepts like confidence intervals, reinforcing your grasp through teaching.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Role Prompting  \n",
        "\n",
        "Now let‚Äôs take things a step further with **role prompting**. Up to this point, we‚Äôve mainly shaped the *content* and *format* of the output. But we can also influence the **voice, style, and perspective** of the model by assigning it a role.  \n",
        "\n",
        "For example, telling the model *‚ÄúYou are an encouraging tutor‚Äù* will lead to friendlier, encouraging study tips, while *‚ÄúYou are a a harsh tutor‚Äù* might result in a more formal and demanding style.  \n",
        "\n",
        "By experimenting with roles, you can align the model‚Äôs responses more closely with your audience or use case.  \n",
        "\n"
      ],
      "metadata": {
        "id": "ac-gU8dsBUaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tips:**\n",
        "\n",
        "- Now that our strings are starting to get longer, we will assign it a variable and pass it in to the function\n",
        "\n",
        "- Furthermore, we will save the model's output as a variable, which is a string."
      ],
      "metadata": {
        "id": "PZabSTxXCmd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouaring_prompt = (\n",
        "    \"You are a encouraging tutor. Adopt this voice consistently.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        ")\n",
        "\n",
        "encouaring_tips = generate_text_simple(encouaring_prompt)\n",
        "print(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-etYVt1Angi",
        "outputId": "7750c011-6788-4c33-cbf1-55ca48754a57"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolutely, you're doing great by seeking additional support! Here are three focused study tips for your statistics course:\n",
            "\n",
            "- **Practice problem-solving:** Regularly work through various problems on sampling distributions to reinforce key concepts and improve your understanding.  \n",
            "- **Visualize data:** Create graphs and charts for data sets to better grasp concepts like correlation and variance.  \n",
            "- **Master hypothesis testing:** Focus on the steps of formulating and testing hypotheses to build confidence in interpreting statistical results.  \n",
            "\n",
            "You've got this! Keep it up!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harsh_prompt = (\n",
        "    \"You are a harsh tutor. Adopt this voice consistently.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        ")\n",
        "\n",
        "harsh_prompt = generate_text_simple(harsh_prompt)\n",
        "print(harsh_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjNVON2XCvFw",
        "outputId": "0ab044ab-5280-4e5c-e692-dbe3975b4613"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Master the difference between descriptive and inferential statistics; it‚Äôs crucial for understanding data and making conclusions.  \n",
            "- Practice calculating probabilities using the binomial and normal distributions; familiarity with these concepts is non-negotiable for success.  \n",
            "- Engage with hypothesis testing by clearly defining null and alternative hypotheses before collecting or analyzing any data.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Analysis\n",
        "\n",
        "Notice the difference in outputs! The **encouraging tutor** fostered collaboration and motivation, while the **harsh tutor** used stronger language like *non-negotiable*, *critical*, and *essential*, emphasizing discipline and high standards.  \n",
        "\n",
        "This shows how just **one line of role prompting** can shift the model‚Äôs tone, style, and choice of words ‚Äî even though the core instructions stayed the same.  \n"
      ],
      "metadata": {
        "id": "AZALfxFHC9-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Role Prompting (System/User)\n",
        "\n",
        "Up to now, we‚Äôve included the role directly inside our prompt text. Another way to guide the model is by using **structured role messages**. With this approach, the API separates instructions into different roles:\n",
        "\n",
        "- **System** ‚Üí defines the overall role, voice, or behavior (e.g., ‚ÄúYou are a supportive tutor‚Äù).  \n",
        "- **User** ‚Üí contains the actual request (e.g., ‚ÄúGive me 3 concise study tips for intro statistics‚Äù).  \n",
        "\n",
        "This structure makes prompts clearer and helps the model stay consistent across longer conversations.  \n",
        "\n",
        "Before wrapping this into a reusable function, let‚Äôs first try it out directly with a our student tips example.  \n"
      ],
      "metadata": {
        "id": "ZFxJu7drF1v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "            \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "            \"Format as bullet points.\\n\"\n",
        "            \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDXyV56aC1HD",
        "outputId": "a22e7e48-7894-41ca-c574-817e50c1afc8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Practice calculating probabilities using the addition and multiplication rules to strengthen your understanding of basic probability concepts.  \n",
            "- Work on real-world examples of hypothesis testing to better grasp concepts like p-values and confidence intervals.  \n",
            "- Regularly review and visualize different types of data distributions to become more comfortable with concepts like normality and skewness.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "Nice! We got supportive and encouraging output. One good practice is to define `system_message` and `user_message` as variables ‚Äî this keeps things cleaner and easier to edit, letting you quickly change tone or instructions without digging into the API call itself.  \n"
      ],
      "metadata": {
        "id": "Pt_Mc67BsjIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        ")\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_GFAL-9n5Ey",
        "outputId": "b9200c48-6ded-4d7b-8a70-3df7962d9fcb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Practice calculating measures of central tendency and variability using real-world datasets to enhance your understanding of data distribution.\n",
            "\n",
            "- Regularly work on probability problems, focusing on concepts like permutations and combinations, to solidify your grasp of foundational principles.\n",
            "\n",
            "- Engage in group study sessions to collaboratively solve hypothesis testing scenarios, discussing p-values and significance levels for deeper comprehension.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Great! Let's put now wrap this into a function!"
      ],
      "metadata": {
        "id": "J4aVU0Lb0zaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_user_prompt(system_message: str, user_message: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"\n",
        "    Send a System/User pair and return the assistant's reply text.\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ]\n",
        "    )\n",
        "    return resp.choices[0].message.content"
      ],
      "metadata": {
        "id": "14TuKHiRwWVb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an harsh and strict tutor. Adopt this voice consistently\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        ")\n",
        "\n",
        "print(system_user_prompt(system_message, user_message))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WWBcMz620b3",
        "outputId": "a1a1bc74-b5d0-44fb-bdf1-6f3fbb6864f0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Master the concepts of descriptive statistics; summarize data using measures of central tendency and variability effectively.  \n",
            "- Practice solving problems on probability distributions; understand normal, binomial, and Poisson distributions thoroughly.  \n",
            "- Develop a strong grasp of hypothesis testing; distinguish between null and alternative hypotheses, and compute p-values accurately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Temperature  \n",
        "\n",
        "One parameter you can adjust is the [temperature](https://platform.openai.com/docs/faq/how-should-i-set-the-temperature-parameter#how-should-i-set-the-temperature-parameter), which controls the **randomness** of the model‚Äôs output.  \n",
        "\n",
        "- A value closer to **0** ‚Üí more deterministic, consistent responses.  \n",
        "- Higher values (closer to **1.0**) ‚Üí more varied and creative responses.  \n",
        "- The maximum allowed temperature is **2.0**.  \n",
        "\n",
        "If you‚Äôd like to dive deeper, check out [this article on LLM temperature](https://www.hopsworks.ai/dictionary/llm-temperature). **Note:** This reading is optional.  \n",
        "\n",
        "Let's add a temperature parameter to our `system_user_prompt` function, and experiment!"
      ],
      "metadata": {
        "id": "JxlzrNTvlHGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_user_prompt(\n",
        "    system_message: str,\n",
        "    user_message: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    temperature: float = 1.0\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Send a System/User pair and return the assistant's reply text.\n",
        "\n",
        "    Parameters:\n",
        "        system_message (str): The role/behavior instruction for the model.\n",
        "        user_message (str): The actual task or question.\n",
        "        model (str): Model name to use (default: gpt-4o-mini).\n",
        "        temperature (float): Controls randomness in output (default: 1.0).\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return resp.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "u-JcPsRn24ec"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###\n",
        "\n",
        "Let‚Äôs change up the prompt! We‚Äôll ask GPT to write poetry by setting the **system** as a creative poet and requesting a **4-line poem about rain**."
      ],
      "metadata": {
        "id": "BzAwPfNmxtgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a creative poet.\"\n",
        "user_message = \"Write a short 4-line poem about rain.\""
      ],
      "metadata": {
        "id": "hvOSDFyuxYO0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will experiment with **3 different temperatures**:  \n",
        "- The default temperature **1.0**  \n",
        "- A less random temperature **0.2**  \n",
        "- A highly random temperature **1.8**  \n",
        "\n",
        "To see how randomness changes the output, we‚Äôll call the API **3 times for each temperature** in a [loop](https://www.w3schools.com/python/python_for_loops.asp). We add a 10-second pause between each run using `time.sleep(10)`. This pause helps avoid hitting API rate limits when making multiple requests in quick succession.\n",
        "\n"
      ],
      "metadata": {
        "id": "0mkB7fFE8zt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.0) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=1.0))\n",
        "    if i < 2:\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGK5bzMl7Zc3",
        "outputId": "8462bd0d-5d97-4e36-b584-dc0e02a75d51"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.0) ‚Äî\n",
            "Whispers fall from clouded skies,  \n",
            "Nature‚Äôs tears in sweet reprise.  \n",
            "Dancing drops on thirsty ground,  \n",
            "Life awakens all around.\n",
            "\n",
            "‚Äî Run 2 (temp=1.0) ‚Äî\n",
            "Whispers of the sky in silver threads,  \n",
            "Dancing droplets weave on thirsty beds,  \n",
            "Nature‚Äôs tears bring life, a sweet refrain,  \n",
            "In every sigh, the earth hums back with rain.\n",
            "\n",
            "‚Äî Run 3 (temp=1.0) ‚Äî\n",
            "Whispers of droplets kiss the ground,  \n",
            "Nature‚Äôs soft symphony, a gentle sound.  \n",
            "Each tear from the sky, a blessing bestowed,  \n",
            "In silver cascades, the world‚Äôs heart glowed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "These three poems at temperature = 1.0 show a balance of variety and consistency. Each output uses gentle, predictable imagery like whispers, droplets, and nature, but the phrasing and rhythm shift slightly with each run. This illustrates how the default temperature produces outputs that are creative yet still fairly stable across generations."
      ],
      "metadata": {
        "id": "RYOxSHC2Ib2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature `0.2`"
      ],
      "metadata": {
        "id": "zRqQP76ZzA-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=0.2) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=0.2))\n",
        "    if i < 2:  # no need to sleep after the last run\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3JXl8U1y-q5",
        "outputId": "6681a8b2-e889-4982-ad2a-5e5f7c63a804"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=0.2) ‚Äî\n",
            "Whispers fall from skies of gray,  \n",
            "Dancing droplets, soft ballet.  \n",
            "Nature's tears, a sweet refrain,  \n",
            "In their rhythm, life‚Äôs embrace‚Äîrain.\n",
            "\n",
            "‚Äî Run 2 (temp=0.2) ‚Äî\n",
            "Whispers of silver from clouds above,  \n",
            "Dance on the rooftops, a gentle love.  \n",
            "Each drop a story, a soft refrain,  \n",
            "Nature's embrace in the heart of the rain.\n",
            "\n",
            "‚Äî Run 3 (temp=0.2) ‚Äî\n",
            "Whispers of silver from clouds above,  \n",
            "Dance on the rooftops, a tender love.  \n",
            "Each drop a story, a soft refrain,  \n",
            "Nature's embrace in the gentle rain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "At temperature = 0.2, the poems are highly consistent, with repeated imagery like whispers of silver and dancing droplets. The structure and tone stay nearly identical across runs, showing how a low temperature makes the model more deterministic and less creative. The outputs feel polished but with less variety compared to higher settings."
      ],
      "metadata": {
        "id": "4XGSTCf5JalE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature `1.8`"
      ],
      "metadata": {
        "id": "5R14lCUW8Xjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.8) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=1.8))\n",
        "    if i < 2:  # no need to sleep after the last run\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z2pDIIAzWHL",
        "outputId": "c8546f12-f995-40ad-c3bd-37fca1efabb1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.8) ‚Äî\n",
            "Whispers of droplets in a soft practice,  \n",
            "Dance upon roofs with a gentle crafter's lavs,‚Äî  \n",
            "In clinks and in flashes, they shimmer in vain,  \n",
            "Nature's sweet lullaby‚Äîbrace for the rain.\n",
            "\n",
            "‚Äî Run 2 (temp=1.8) ‚Äî\n",
            "Gentle whispers tumbling down,  \n",
            "Like silver threads in twilight's gown.  \n",
            "Dancing leaves in puddles fain,  \n",
            "Heartbeats wooed by soft Spring rain.\n",
            "\n",
            "‚Äî Run 3 (temp=1.8) ‚Äî\n",
            "Silver droplets dance and soak the ground,  \n",
            "Life awakened, without a single sound,  \n",
            "Whispers of nature, tender and light,  \n",
            "In the motherly chays of the deepening night.   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "At temperature = 1.8, the poems show much more variety and imaginative phrasing, such as calm swarm or dusty dreams. The imagery shifts noticeably between runs, with less repetition and more surprising word choices. This demonstrates how a high temperature boosts creativity and randomness, though it can also lead to less polished or less consistent results."
      ],
      "metadata": {
        "id": "9bPIOp_lJk6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Markdown Formatting  \n",
        "\n",
        "So far, we have seen the LLM's raw output. However, we can make our results more readable by asking the model to format responses in **Markdown**. This will help us generate outputs that look cleaner and are easier to interpret inside Colab or on GitHub. This is especially useful when working with structured content such as study guides, rubrics, or summaries.\n",
        "\n",
        "We can create a function called `to_markdown`, which we will call whenever we want to render the model‚Äôs text as formatted Markdown (headings, lists, bold/italics) instead of plain text.\n"
      ],
      "metadata": {
        "id": "p0QO78dcLxyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    # Convert the provided text to Markdown format for better display in Jupyter Notebooks\n",
        "    return Markdown(text)"
      ],
      "metadata": {
        "id": "aEVCoqPhOQvt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out with the `encouaring_tips` variable we created earlier!"
      ],
      "metadata": {
        "id": "mWN_i6iTWukY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "3EDQFXHhwR-D",
        "outputId": "49b83537-2463-4caa-f905-3645fa427866"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Absolutely, you're doing great by seeking additional support! Here are three focused study tips for your statistics course:\n\n- **Practice problem-solving:** Regularly work through various problems on sampling distributions to reinforce key concepts and improve your understanding.  \n- **Visualize data:** Create graphs and charts for data sets to better grasp concepts like correlation and variance.  \n- **Master hypothesis testing:** Focus on the steps of formulating and testing hypotheses to build confidence in interpreting statistical results.  \n\nYou've got this! Keep it up!"
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See! Our output is much cleaner!"
      ],
      "metadata": {
        "id": "XI551XFMw4-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Forward  \n",
        "\n",
        "Congrats! You now have the basics of prompt engineering. üéâ  \n",
        "Next, we‚Äôll apply these skills to a real use case ‚Äî showing how LLMs can generate an essay, design a rubric, and then grade the essay based on that rubric.  \n"
      ],
      "metadata": {
        "id": "kuF1QiUE7yae"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9D-85OEydPu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}