{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlIR0VgaFr0hLBi94PGmon",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Generative%20AI%20Getting%20Started%20Part%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI Getting Started (Part 1)\n",
        "\n",
        "Welcome to **Generative AI Getting Started (Part 1)**. In this notebook, you‚Äôll learn the fundamentals of **prompt engineering** through a step-by-step tutorial. By the end, you‚Äôll be able to:\n",
        "\n",
        "- Create and store an OpenAI API key  \n",
        "- Apply core prompt engineering strategies (iteration and refinement)  \n",
        "- Use practical coding patterns to streamline your workflow  \n",
        "\n",
        "These skills are not only valuable for this project, but they will also help you stand out in industry. In fact, Andrew Ng [notes](https://www.linkedin.com/posts/andrewyng_there-is-significant-unmet-demand-for-developers-activity-7369397355160272898-i85T?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAUuuFIBPjBR1kCVBdoY03J3r6hwaAwvapU) that some of the key abilities he looks for when interviewing AI engineers include:  \n",
        "\n",
        "- Using AI building blocks like prompting, RAG, evals, agentic workflows, and machine learning to build applications  \n",
        "- Prototyping and iterating rapidly  \n",
        "\n",
        "You‚Äôll get to practice both of these in this workshop.  \n",
        "\n",
        "Let‚Äôs dive in and start building! üöÄ\n",
        "\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "h0D-mCSmF4fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. Getting Started with OpenAI\n",
        "\n",
        "    - Step 1: OpenAI\n",
        "\n",
        "    - Step 2: Authentication\n",
        "\n",
        "    - Step 3: Creating a New Secret Key\n",
        "\n",
        "    - Step 4: Creating the Key\n",
        "\n",
        "    - Step 5: Saving Your Key\n",
        "\n",
        "    - Next Steps\n",
        "\n",
        "2. Saving Your API Key in Colab\n",
        "\n",
        "3. Loading and Veriyfing your Key üîë\n",
        "\n",
        "4. Prompt Engineering\n",
        "\n",
        "    - Minimal Test\n",
        "\n",
        "5. Prompt Engineering Tips\n",
        "    \n",
        "    - Adding More Detail\n",
        "\n",
        "    - Controlling Length\n",
        "\n",
        "    - Guide Style\n",
        "\n",
        "    - Consistent Structure\n",
        "\n",
        "6. Creating Function\n",
        "\n",
        "    - First Prompt\n",
        "\n",
        "    - Second Prompt\n",
        "\n",
        "    - Third Prompt\n",
        "\n",
        "    - Fourth Prompt\n",
        "\n",
        "    - Fifth Prompt\n",
        "\n",
        "7. Role Prompting\n",
        "\n",
        "\n",
        "8. Role Prompting (System/User)\n",
        "\n",
        "9. Temperature\n",
        "\n",
        "   - Temperature 0.2\n",
        "\n",
        "   - Temperature 1.8\n",
        "\n",
        "10. Markdown Formatting\n",
        "\n",
        "11. Forward\n",
        "\n",
        "-----\n"
      ],
      "metadata": {
        "id": "a3TFltMM6-BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 id=\"getting-started\">1. Getting Started with OpenAI</h2>\n",
        "\n",
        "In this notebook, we will help you get started working with OpenAI's API.  \n"
      ],
      "metadata": {
        "id": "9DOXu1ULLQ-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: OpenAI  \n",
        "\n",
        "Click this link to open [OpenAI](https://openai.com/). In the top-right corner, hover over **Log In** and select **API Platform**, as shown in the image below.  \n"
      ],
      "metadata": {
        "id": "NcAUE-qhMoqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_1.png?raw=true\">"
      ],
      "metadata": {
        "id": "SWmQGCh95aah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Authentication  \n",
        "\n",
        "After signing in (and entering the verification code sent to your email), you will be directed to the page shown below. Under **Authentication**, click <u>Organization settings</u>.  \n"
      ],
      "metadata": {
        "id": "8ai80iO7MtjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_2.png?raw=true\">"
      ],
      "metadata": {
        "id": "fvmIkb_K5dQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Creating a New Secret Key  \n",
        "\n",
        "After clicking <u>Organization settings</u>, you will be taken to the page shown below. From there, click **Create new secret key**.  \n"
      ],
      "metadata": {
        "id": "9ASw4lDf4qSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_3.png?raw=true\">"
      ],
      "metadata": {
        "id": "mAKiVFJ_5Bvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Creating the Key  \n",
        "\n",
        "After clicking **Create new secret key**, a pop-up will appear. While entering a name is optional, it is recommended to use something meaningful (e.g., *Fall 2025 Practicum*). Next, select **Default project** and ensure **All** is selected. Finally, click **Create secret key**.  \n"
      ],
      "metadata": {
        "id": "3aT5Qh835c1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_4.png?raw=true\">"
      ],
      "metadata": {
        "id": "-ZbPe1Rz557Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Saving Your Key  \n",
        "\n",
        "After creating the key, it will appear as shown below (mine is hidden for privacy).  \n",
        "\n",
        "1. Click **Copy** and save your key somewhere safe‚Äîyou won‚Äôt be able to view it again later.  \n",
        "2. Do **not** share your key. Using an OpenAI key incurs costs, and you will be charged if someone else uses it.  "
      ],
      "metadata": {
        "id": "MfzG8I2V5b0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_5.png?raw=true\">"
      ],
      "metadata": {
        "id": "Qdi0Mg3_56wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps\n",
        "\n",
        "Congrats! You now made your OpenAI Key. Now, this is where the fun part begins. We can finally utilize the key.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "YGNlDDkN5w1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Saving Your API Key in Colab üîë\n",
        "\n",
        "Before using OpenAI's API, we need a secure way to store the API key in this notebook.  \n",
        "Google Colab provides a built-in secrets manager for this purpose.  \n",
        "\n",
        "\n",
        "### Step 1:\n",
        "On the left sidebar, click on the **key icon**.  \n",
        "\n",
        "### Step 2:\n",
        "Click **‚ÄúAdd new secret.‚Äù**  \n",
        "\n",
        "### Step 3:\n",
        "- Paste your API key into the **Value** field  \n",
        "- Give it a descriptive **Name** (e.g., `OPENAI_API_KEY`)  \n",
        "- Ensure **Notebook access** is enabled  \n"
      ],
      "metadata": {
        "id": "Bu1FZjF_62yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/Sam-Gartenstein/GenAI-Engineering-Workshop/blob/main/Screen_Shots/OpenAI_Image_6.png?raw=true\" width=\"500\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "GVvXAhCE-3MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Once entered, you can hit the exit button. Your API key will be  stored automatically and available for use in your notebook.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "nqBl6zeD-2Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading and Verifying Your API Key üîë\n",
        "\n",
        "We load the API key from Colab Secrets into an environment variable so Python packages can access it.  \n",
        "The check then verifies whether `OPENAI_API_KEY` is set:  \n",
        "\n",
        "- If the key is missing, a clear **RuntimeError** is raised so you know to add it in Colab Secrets.  \n",
        "- If the key is found, it safely confirms with `True` without ever printing the actual secret.  \n",
        "\n",
        "However, before we do this, we must import `openai`'s library.\n",
        "\n",
        "<br>  \n",
        "\n",
        "**‚ú® Optional Learning**  \n",
        "- `google.colab.userdata`: Secure interface to Colab‚Äôs Secrets; lets you fetch saved keys (e.g., `userdata.get(\"OPENAI_API_KEY\")`).  \n",
        "- `os`: Standard library module for interacting with the operating system ‚Äî here, used to read/set environment variables (`os.getenv`, `os.environ`).  "
      ],
      "metadata": {
        "id": "ISid8s8DDBKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "hHEhlVltMWup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Pull your saved secret into an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Test if the key is available (without printing it)\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise RuntimeError(\"OPENAI_API_KEY is not set. Add it via Colab Secrets (üîë) and try again.\")\n",
        "else:\n",
        "    print(\"Key loaded?\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dxACnFdC8Nj",
        "outputId": "78d21a96-469b-4e16-805c-7da534ac1d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key loaded? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "If you see `Key loaded? True`, then everything is working and you‚Äôre ready to move on to the next step.  \n",
        "\n",
        "<br>\n",
        "\n",
        "If you see the error, please make sure that:  \n",
        "- You saved your API key in Colab‚Äôs **üîë Secrets** panel.  \n",
        "- The secret is named exactly **`OPENAI_API_KEY`** (no typos or extra spaces).  \n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "nErn9WnmH8KT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Prompt Engineering\n",
        "\n",
        "Congrats! You have your key loaded. Now, this is where the fun part begins.\n"
      ],
      "metadata": {
        "id": "gY1tLiJEJWbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Minimal Test\n",
        "\n",
        "Below, you will run your first **end-to-end test with the OpenAI API** ‚Äî creating a client, sending a simple prompt, and viewing the model‚Äôs reply.  \n",
        "\n",
        "The first line\n",
        "\n",
        "```python\n",
        "client = OpenAI() `\n",
        "```\n",
        "\n",
        "Creates an OpenAI client that knows how to talk to the API. It automatically picks up your API key from `OPENAI_API_KEY`, which you saved earlier in Colab‚Äôs Secrets.\n",
        "\n",
        "The next three lines:\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "```\n",
        "\n",
        "- Sends a **request** to the Responses API\n",
        "- `model=\"gpt-4o-mini\"` selects the model\n",
        "- `input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"` is your prompt\n",
        "- The full structured result (text + metadata) is stored in `resp`\n",
        "\n",
        "Finally:\n",
        "\n",
        "```python\n",
        "print(resp.output_text)\n",
        "```\n",
        "\n",
        "Extracts just the generated text from the response object and prints it.\n",
        "\n",
        "<br>\n",
        "\n",
        "That‚Äôs it! We follow this process: create a client ‚Üí send a prompt ‚Üí print the model‚Äôs reply."
      ],
      "metadata": {
        "id": "115lW5IyJS4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()  # uses OPENAI_API_KEY already in your env\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me study tips. Each study point should be fairly short, a few sentences only.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu1AeBQBC_0o",
        "outputId": "024bff73-060b-4972-ac0a-3e07edf4011a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some concise study tips:\n",
            "\n",
            "1. **Set Clear Goals**: Define specific, achievable goals for each study session to maintain focus and motivation. \n",
            "\n",
            "2. **Create a Schedule**: Plan sessions with a consistent routine. Incorporate breaks to help refresh your mind and improve retention.\n",
            "\n",
            "3. **Active Learning**: Engage with the material through summarizing, teaching concepts to others, or applying information to real-life scenarios.\n",
            "\n",
            "4. **Use Mnemonics**: Create acronyms, rhymes, or visual images to help remember complex information easily.\n",
            "\n",
            "5. **Practice Retrieval**: Test yourself regularly on the material. Quizzing enhances memory retention significantly.\n",
            "\n",
            "6. **Stay Organized**: Keep notes and study materials organized. Use folders or apps to keep track of important documents.\n",
            "\n",
            "7. **Limit Distractions**: Find a quiet study space and silence notifications to maintain concentration on your tasks.\n",
            "\n",
            "8. **Review Regularly**: Periodic review of material over time (spaced repetition) strengthens memory and understanding.\n",
            "\n",
            "9. **Healthy Lifestyle**: Prioritize sleep, nutrition, and exercise. A healthy body supports a focused and alert mind.\n",
            "\n",
            "10. **Group Study**: Collaborate with peers for discussions. Sharing insights can deepen understanding and facilitate learning.\n",
            "\n",
            "11. **Utilize Resources**: Turn to textbooks, videos, or online courses to diversify your understanding of difficult topics.\n",
            "\n",
            "12. **Stay Positive**: Keep a positive mindset. Self-encouragement can reduce anxiety and improve performance in studies.\n",
            "\n",
            "13. **Visual Aids**: Use charts, diagrams, and flashcards to represent information visually, making it easier to comprehend and remember.\n",
            "\n",
            "14. **Ask for Help**: Don't hesitate to seek clarification from teachers or classmates when you're stuck on a concept.\n",
            "\n",
            "15. **Mindfulness and Relaxation**: Incorporate mindfulness techniques or short meditations to reduce stress and enhance concentration. \n",
            "\n",
            "Utilize these tips to boost your studying effectiveness!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "## 5. Prompt Engineering Tips  \n",
        "\n",
        "Congrats! You just used OpenAI‚Äôs API to prompt üéâ You‚Äôre a pro already! However, like any good pro, there‚Äôs always room for improvement.  \n",
        "\n",
        "While the output may look fine, our prompt is actually **‚Äúfluffy.‚Äù** It leaves too much room for interpretation ‚Äî words like *‚Äúfairly short‚Äù* or *‚Äúa few sentences‚Äù* are vague and can lead to inconsistent or overly long responses.  \n",
        "\n",
        "To fix this, we turn to **prompt engineering**. By carefully shaping your prompt, you can guide the model to produce responses that are **shorter, more specific, and better formatted**.  \n",
        "\n",
        "A few helpful strategies:  \n",
        "- **Be precise**: Reduce ‚Äúfluffy‚Äù or vague descriptions in your prompt.  \n",
        "- **Set boundaries**: Specify the number of items you want (e.g., ‚ÄúGive me 3 tips‚Äù).  \n",
        "- **Control format**: Ask for bullet points, numbered lists, or concise sentences.  \n",
        "- **Guide style**: Indicate the tone or audience (‚ÄúExplain this like I‚Äôm a high school student‚Äù).  \n",
        "\n",
        "With these small adjustments, you gain much more control over the **length, style, and clarity** of the output.  \n",
        "\n",
        "<br>\n",
        "\n",
        "Let‚Äôs start by reducing the **‚Äúfluffy‚Äù** description. Instead of leaving things vague, we‚Äôll make the prompt more precise and test how that changes the output.\n"
      ],
      "metadata": {
        "id": "oJWnJsB4O7to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me three concise study tips. The output should be bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7yhFEkZKp7k",
        "outputId": "766a3fb8-c7b4-4fa4-b80a-82d6542ab86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Active Recall:** Test yourself on the material instead of just rereading notes to enhance retention.\n",
            "- **Pomodoro Technique:** Study in focused bursts (25 minutes), followed by short breaks (5 minutes) to maintain concentration and prevent burnout.\n",
            "- **Organized Notes:** Keep notes structured and clear, using headings and bullet points for easier review and organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding More Detail\n",
        "\n",
        "Nice! We guided the model to generate only three points. We set a **boundary** and **controlled** the format! Now, let‚Äôs refine the prompt further by adding more detail about how each tip should look. Although the original output may be sentences, since we **DID NOT** specify this originally, lets ensure that they are always outputted as sentences.\n"
      ],
      "metadata": {
        "id": "EDMad53OVkVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me exactly 3 study tips, each in one sentence. Format the output as bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeo2f8otToNy",
        "outputId": "83cc4314-3932-45cb-f247-6ef174eb5e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Use active recall by testing yourself on the material instead of just re-reading notes to enhance retention.  \n",
            "- Break study sessions into focused intervals, such as the Pomodoro Technique (25 minutes of study followed by a 5-minute break), to maintain concentration.  \n",
            "- Organize your study materials and create a structured outline to help visualize the connections between concepts.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Controlling Length  \n",
        "\n",
        "Great! We added another instruction to the prompt, telling the model that each tip should be one sentence. However, you may notice that some of the tips are still quite long. To tighten things up even more, we can add another constraint: limit each tip to **20 words or fewer**.  \n"
      ],
      "metadata": {
        "id": "FJfy5nqhX_68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Give me exactly 3 study tips. Each tip should be one sentence (‚â§ 20 words). Format as bullet points.\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coVJMmzsTocm",
        "outputId": "307acfb7-f225-4347-f9ac-83847ee341d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Break your study sessions into focused intervals, using techniques like the Pomodoro Technique for better retention.  \n",
            "- Create a quiet, organized study space to minimize distractions and maximize concentration.  \n",
            "- Summarize key concepts in your own words to reinforce understanding and recall.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guide Style  \n",
        "\n",
        "Great! Now we‚Äôve made our tips more concise. But we can also **tailor them to a specific audience or context**. After all, not every subject will require the same study strategies.  \n",
        "\n",
        "Let‚Äôs adjust the prompt to target a particular audience ‚Äî for example, students in a **college-level introductory statistics course**. Along with our earlier instructions (exactly 3 tips, one sentence each, ‚â§ 20 words, formatted as bullet points), we‚Äôll also ask the model to be **concrete and domain-specific** by referencing ideas like *sampling, probability, or hypothesis testing*.  \n",
        "\n",
        "**Concept:** Notice the `\\n` in the prompt. This adds a line break inside the string, making multi-step instructions clearer for both you and the model.  \n"
      ],
      "metadata": {
        "id": "aCANEu7FZlJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\n",
        "        \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "        \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "        \"Format as bullet points.\\n\"\n",
        "        \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo7ErNYyX63A",
        "outputId": "0c424788-c5c8-41ce-9608-ba53ec89755c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Practice with real data**: Use datasets to apply concepts like sampling, mean, median, variance, and standard deviation in practical scenarios.  \n",
            "- **Work through hypothesis tests**: Understand the steps for conducting and interpreting t-tests and chi-square tests to strengthen statistical reasoning.  \n",
            "- **Visualize concepts**: Create graphs and charts to represent distributions, probabilities, and relationships, enhancing comprehension of statistical ideas.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consistent Structure  \n",
        "\n",
        "Look at that! We‚Äôve created three amazing study tips! Well, GPT did ‚Äî but it couldn‚Äôt have done it without our help and thoughtful prompting.  \n",
        "\n",
        "However, you may notice that the **formatting isn‚Äôt always consistent** after running the prompt. Sometimes the model adds a **tip title** (e.g., **Active Recall**) before the explanation, while other times it just writes the explanation itself.  \n",
        "\n",
        "To improve readability, we can adjust our prompt to request a **consistent structure** ‚Äî for example, always starting with a bolded tip title followed by a short explanation. One effective way to do this is with **one-shot prompting**, where we include a single example for the model to imitate.  \n"
      ],
      "metadata": {
        "id": "lvQccyHzftAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\n",
        "        \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "        \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "        \"Format as bullet points.\\n\"\n",
        "        \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\\n\"\n",
        "        \"\\n\"\n",
        "        \"Example (match structure exactly):\\n\"\n",
        "        \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "        \"\\n\"\n",
        "        \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nb54ZiZgX66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87c7a90-ec58-404f-e52a-1d1bccb5812c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ä¢ **Visualization:** Create graphs and charts to understand data distributions and relationships in statistical concepts better.  \n",
            "\n",
            "‚Ä¢ **Practice Problems:** Regularly solve problems on hypothesis tests and confidence intervals to reinforce your understanding and application skills.  \n",
            "\n",
            "‚Ä¢ **Study Groups:** Join or form study groups to discuss and explain concepts like p-values and confidence levels with peers.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üéâ Congrats! You‚Äôre well on your way to becoming a prompt engineering pro!  \n",
        "\n",
        "As you‚Äôve seen, this is an **iterative process** ‚Äî each step builds on the last, and small adjustments to your instructions can lead to big improvements in the model‚Äôs output.  \n",
        "\n",
        "Let‚Äôs keep building on this strong foundation!\n",
        "\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "vLmi7a9d5N8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Creating Function  \n",
        "\n",
        "By now, you‚Äôve probably noticed that we‚Äôre repeating the same code again and again. That‚Äôs not very efficient!  \n",
        "\n",
        "To fix this, we can create a **function**. Functions are a staple in programming and data science ‚Äî they let you **bundle code into a reusable block**. Instead of copying and pasting the same lines, you simply call the function by name whenever you need it.  \n",
        "\n",
        "This makes your code **cleaner, more efficient, and easier to maintain** as your project grows.  \n",
        "\n",
        "We will call our first function, `generate_text_simple`. Inside our function, we have\n",
        "\n",
        "```python\n",
        "resp = client.responses.create(\n",
        "    model=model,\n",
        "    input=prompt\n",
        ")\n",
        "\n",
        "return resp.output_text\n",
        "```\n",
        "\n",
        "Inside the function, we accept two arguments ‚Äî the **prompt** and an optional **model** (default: `\"gpt-4o-mini\"`). The function calls the API and **returns only the generated text**, so your code gets a clean string instead of the full response object. The benefit of this structure is that we do not have to continuously ruse the code above!\n"
      ],
      "metadata": {
        "id": "eLUf3jOyc4e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"\n",
        "    Send a prompt to an OpenAI model and return the generated text.\n",
        "\n",
        "    Args:\n",
        "        prompt: The input text/prompt.\n",
        "        model:  The model name to use (default: gpt-4o-mini).\n",
        "\n",
        "    Returns:\n",
        "        The model's text output.\n",
        "    \"\"\"\n",
        "    resp = client.responses.create(\n",
        "        model=model,\n",
        "        input=prompt\n",
        "    )\n",
        "    return resp.output_text"
      ],
      "metadata": {
        "id": "EegVxTPBVBN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we will call the with **all** of the prompts we have used so far. This will demonstrate the effiency.\n",
        "\n",
        " To call a function, simply write its name followed by parentheses and provide the required arguments inside. In our case, we are only passing the **prompt**, since we already defined a default **model** inside the function.  \n",
        "\n",
        "**Tip:** For cleaner formatting of the output, wrap the function call inside a `print()` statement.  \n"
      ],
      "metadata": {
        "id": "eWNwtKEHRvUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Prompt"
      ],
      "metadata": {
        "id": "Suv4LFfH-C0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\"Give me study tips. Each study point should be fairly short, a few sentences only.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUS-Q-w2RDfp",
        "outputId": "b5b49d22-890f-4383-a7b9-9e9fe934cbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are some concise study tips:\n",
            "\n",
            "1. **Set Specific Goals**: Define clear, achievable study goals for each session to maintain focus and direction. Break larger topics into manageable parts.\n",
            "\n",
            "2. **Create a Schedule**: Develop a consistent study routine, allocating specific time slots for different subjects. Stick to your schedule to build a habit.\n",
            "\n",
            "3. **Active Learning**: Engage with the material through summarization, teaching it to someone else, or creating mind maps. This reinforces comprehension.\n",
            "\n",
            "4. **Use the Pomodoro Technique**: Study for 25 minutes, then take a 5-minute break. This enhances concentration and helps prevent burnout.\n",
            "\n",
            "5. **Eliminate Distractions**: Find a quiet study environment and limit digital distractions by using apps that block notifications.\n",
            "\n",
            "6. **Practice Retrieval**: Test yourself frequently by using flashcards or practice quizzes. This reinforces memory and highlights areas needing review.\n",
            "\n",
            "7. **Stay Organized**: Keep your notes, materials, and study space tidy. An organized environment reduces stress and enhances focus.\n",
            "\n",
            "8. **Utilize Various Resources**: Explore different study materials such as videos, podcasts, or books to gain diverse perspectives and better understanding.\n",
            "\n",
            "9. **Stay Healthy**: Prioritize sleep, nutrition, and exercise. A healthy body supports a sharp mind, improving learning and retention.\n",
            "\n",
            "10. **Join Study Groups**: Collaborating with peers can provide new insights, encourage accountability, and make studying more enjoyable.\n",
            "\n",
            "11. **Use Visual Aids**: Incorporate diagrams, charts, or drawings into your notes to visualize complex information, which can enhance understanding.\n",
            "\n",
            "12. **Stay Positive**: Maintain a positive mindset, celebrate small achievements, and remind yourself of your end goals to stay motivated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Prompt"
      ],
      "metadata": {
        "id": "LDLZiM9L-MLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\"Give me three concise study tips. The output should be bullet points.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EA7cFWs93aI",
        "outputId": "ff299416-05c9-45ae-8bf0-9148acf4b43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Active Recall:** Test yourself on the material instead of just rereading notes to enhance memory retention.  \n",
            "- **Spaced Repetition:** Revise information at increasing intervals over time to strengthen long-term retention.  \n",
            "- **Study Environment:** Choose a quiet, organized space free from distractions to improve focus and productivity.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Third Prompt"
      ],
      "metadata": {
        "id": "voMJTuaC8jlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\"Give me exactly 3 study tips. Each tip should be one sentence (‚â§ 20 words). Format as bullet points.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud-JGI9J-SE-",
        "outputId": "d53264d0-c541-445b-fde4-5a1bbbb87391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Break study sessions into focused intervals with short breaks to enhance retention and reduce fatigue.  \n",
            "- Use active recall by testing yourself on the material to improve memory and understanding.  \n",
            "- Summarize concepts in your own words to reinforce comprehension and identify gaps in knowledge.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourth Prompt"
      ],
      "metadata": {
        "id": "9LtxwREx-pGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\"\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcB5AHWc-hHi",
        "outputId": "fd9a7a80-07e8-4ffd-b8e0-cf62ddfc259e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Practice interpreting various sampling methods and their impacts on data validity in real-world scenarios.  \n",
            "- Regularly solve problems involving probability distributions to gain a solid understanding of concepts like normal and binomial distributions.  \n",
            "- Master hypothesis testing by conducting and analyzing your own experiments to reinforce concepts of p-values and significance levels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fifth Prompt"
      ],
      "metadata": {
        "id": "KziLiOFo_fDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text_simple(\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., concepts like sampling, probability, hypothesis tests).\\n\"\n",
        "    \"\\n\"\n",
        "    \"Example (match structure exactly):\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILyLurLR-qAZ",
        "outputId": "d8a2be52-e053-4b5e-f93f-0ddaff0e4fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ä¢ **Visualization:** Create graphs for data distributions to better understand concepts like mean, median, and standard deviation.  \n",
            "\n",
            "‚Ä¢ **Practice Problems:** Solve diverse hypothesis testing problems to master p-values and confidence intervals effectively.  \n",
            "\n",
            "‚Ä¢ **Group Study:** Discuss concepts like random samples and the Central Limit Theorem with peers for deeper understanding.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "## 7. Role Prompting  \n",
        "\n",
        "Now let‚Äôs take things a step further with **role prompting**. Up to this point, we‚Äôve mainly shaped the *content* and *format* of the output. But we can also influence the **voice, style, and perspective** of the model by assigning it a role.  \n",
        "\n",
        "For example, telling the model *‚ÄúYou are an encouraging tutor‚Äù* will lead to friendlier, encouraging study tips, while *‚ÄúYou are a a harsh and strict tutor‚Äù* might result in a more formal and demanding style.  \n",
        "\n",
        "By experimenting with roles, you can align the model‚Äôs responses more closely with your audience or use case.  \n",
        "\n"
      ],
      "metadata": {
        "id": "ac-gU8dsBUaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tips:**\n",
        "\n",
        "- Now that our strings are starting to get longer, we will assign it a variable and pass it in to the function\n",
        "\n",
        "- Furthermore, we will save the model's output as a variable, which is a string."
      ],
      "metadata": {
        "id": "PZabSTxXCmd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encouaring_prompt = (\n",
        "    \"You are a encouraging tutor. Adopt this voice consistently.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "encouaring_tips = generate_text_simple(encouaring_prompt)\n",
        "print(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-etYVt1Angi",
        "outputId": "18f83244-8bc5-4651-f51d-58877f866592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolutely, you‚Äôve got this! Here are three more study tips for your statistics course:\n",
            "\n",
            "- **Visual Aids:** Create charts or graphs to visualize concepts like normal distribution and correlation to enhance understanding.\n",
            "\n",
            "- **Study Groups:** Discuss hypothesis testing in study groups to clarify concepts and learn from different perspectives.\n",
            "\n",
            "- **Practice Problems:** Regularly solve past exams and practice problems focused on probability and statistical inference to build confidence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harsh_prompt = (\n",
        "    \"You are a harsh and strict tutor. Adopt this voice consistently.\\n\"\n",
        "    \"Give me exactly 3 study tips for students in a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\\n\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "harsh_prompt = generate_text_simple(harsh_prompt)\n",
        "print(harsh_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjNVON2XCvFw",
        "outputId": "c335f70a-1cdc-4c0e-e2b2-4d20b6beeb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Understand the Central Limit Theorem:** Master how sample means behave as sample size increases; it's crucial for hypothesis testing.  \n",
            "- **Use Real-World Data:** Analyze actual datasets to grasp concepts like correlation and regression; theory alone is insufficient.  \n",
            "- **Visualize Distributions:** Graph normal, binomial, and other distributions to solidify your understanding of variability and probability.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Anaylsis**\n",
        "\n",
        "Notice the difference in outputs! The **encouraging tutor** fostered collaboration and motivation, while the **harsh tutor** used stronger language like *non-negotiable*, *critical*, and *essential*, (this may vary with each run)  emphasizing discipline and high standards.  \n",
        "\n",
        "This shows how just **one line of role prompting** can shift the model‚Äôs tone, style, and choice of words ‚Äî even though the core instructions stayed the same.  \n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "AZALfxFHC9-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Role Prompting (System/User)\n",
        "\n",
        "Up to now, we‚Äôve included the role directly inside our prompt text. Another way to guide the model is by using **structured role messages**. With this approach, the API separates instructions into different roles:\n",
        "\n",
        "- **System** ‚Üí defines the overall role, voice, or behavior (e.g., ‚ÄúYou are a supportive tutor‚Äù).  \n",
        "- **User** ‚Üí contains the actual request (e.g., ‚ÄúGive me 3 concise study tips for intro statistics‚Äù).  \n",
        "\n",
        "This structure makes prompts clearer and helps the model stay consistent across longer conversations.  \n",
        "\n",
        "Before wrapping this into a reusable function, let‚Äôs first try it out directly with a our student tips example.  \n"
      ],
      "metadata": {
        "id": "ZFxJu7drF1v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "            \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "            \"Format as bullet points.\\n\"\n",
        "            \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "            \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "            \"\\n\"\n",
        "            \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDXyV56aC1HD",
        "outputId": "eb8b95b0-dff0-4e35-fe3e-229f068855ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Group Study:** Collaborate with classmates to discuss and solve problems related to hypothesis testing and confidence intervals.  \n",
            "- **Visual Aids:** Create graphs and charts to visualize data distributions and understand concepts like mean, median, and mode.  \n",
            "- **Practice Problems:** Work on real-world scenarios involving probability and sampling techniques to reinforce understanding and application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We got supportive and encouraging output. One good practice is to define `system_message` and `user_message` as variables ‚Äî this keeps things cleaner and easier to edit, letting you quickly change tone or instructions without digging into the API call itself.  \n"
      ],
      "metadata": {
        "id": "Pt_Mc67BsjIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an encouraging tutor. Be supportive, practical, and foster collaboration.\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_GFAL-9n5Ey",
        "outputId": "ec6d8c3a-1694-464e-8597-3911a32b551f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Visualize Data:** Use graphs and charts to help understand concepts like distributions and averages effectively.  \n",
            "- **Practice Problems:** Regularly solve different types of hypothesis testing scenarios to build your confidence and skills.  \n",
            "- **Collaborative Study:** Form a study group to discuss key concepts such as p-values and confidence intervals for better retention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Let's now wrap this into a function!"
      ],
      "metadata": {
        "id": "J4aVU0Lb0zaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_user_prompt(system_message: str, user_message: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    \"\"\"\n",
        "    Send a System/User pair and return the assistant's reply text.\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ]\n",
        "    )\n",
        "    return resp.choices[0].message.content"
      ],
      "metadata": {
        "id": "14TuKHiRwWVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are an harsh and strict tutor. Adopt this voice consistently\"\n",
        "user_message = (\n",
        "    \"Give me exactly 3 study tips for a college-level introductory statistics course.\\n\"\n",
        "    \"Each tip should be one sentence (‚â§ 20 words).\\n\"\n",
        "    \"Format as bullet points.\\n\"\n",
        "    \"Be concrete and domain-specific (e.g., sampling, probability, hypothesis testing).\"\n",
        "    \"‚Ä¢ **Active Recall:** Test yourself with short quizzes on sampling and probability after each study session.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Now generate exactly 3 new tips, different from the example.\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "print(system_user_prompt(system_message, user_message))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WWBcMz620b3",
        "outputId": "8a7b1a7f-6915-4d0c-bb5b-c043282a7c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Practice Problems:** Solve a variety of hypothesis testing problems to reinforce your understanding of p-values and significance levels.  \n",
            "- **Visual Learning:** Use graphs and charts to interpret data distributions, as visual aids enhance comprehension of statistical concepts.  \n",
            "- **Group Study:** Collaborate with peers to discuss and solve statistical cases, deepening your understanding through diverse problem-solving approaches.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "## 9. Temperature  \n",
        "\n",
        "One parameter you can adjust is the [temperature](https://platform.openai.com/docs/faq/how-should-i-set-the-temperature-parameter#how-should-i-set-the-temperature-parameter), which controls the **randomness** of the model‚Äôs output.  \n",
        "\n",
        "- A value closer to **0** ‚Üí more deterministic, consistent responses.  \n",
        "- Higher values (closer to **1.0**) ‚Üí more varied and creative responses.  \n",
        "- The maximum allowed temperature is **2.0**.  \n",
        "\n",
        "If you‚Äôd like to dive deeper, check out [this article on LLM temperature](https://www.hopsworks.ai/dictionary/llm-temperature). **Note:** This reading is optional.  \n",
        "\n",
        "Let's add a temperature parameter to our `system_user_prompt` function, and experiment!"
      ],
      "metadata": {
        "id": "JxlzrNTvlHGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_user_prompt(\n",
        "    system_message: str,\n",
        "    user_message: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    temperature: float = 1.0\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Send a System/User pair and return the assistant's reply text.\n",
        "\n",
        "    Parameters:\n",
        "        system_message (str): The role/behavior instruction for the model.\n",
        "        user_message (str): The actual task or question.\n",
        "        model (str): Model name to use (default: gpt-4o-mini).\n",
        "        temperature (float): Controls randomness in output (default: 1.0).\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return resp.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "u-JcPsRn24ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###\n",
        "\n",
        "Let‚Äôs change up the prompt! We‚Äôll ask GPT to write poetry by setting the **system** as a creative poet and requesting a **4-line poem about rain**."
      ],
      "metadata": {
        "id": "BzAwPfNmxtgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a creative poet.\"\n",
        "user_message = \"Write a short 4-line poem about rain.\""
      ],
      "metadata": {
        "id": "hvOSDFyuxYO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will experiment with **3 different temperatures**:  \n",
        "- The default temperature **1.0**  \n",
        "- A less random temperature **0.2**  \n",
        "- A highly random temperature **1.8**  \n",
        "\n",
        "To see how randomness changes the output, we‚Äôll call the API **3 times for each temperature** in a [loop](https://www.w3schools.com/python/python_for_loops.asp). We add a 10-second pause between each run using `time.sleep(10)`. This pause helps avoid hitting API rate limits when making multiple requests in quick succession.\n",
        "\n"
      ],
      "metadata": {
        "id": "0mkB7fFE8zt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.0) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=1.0))\n",
        "    if i < 2:\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGK5bzMl7Zc3",
        "outputId": "dae81920-8758-4c0c-81e0-8e9cdafb28b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.0) ‚Äî\n",
            "Whispers dance from silver skies,  \n",
            "A soothing symphony replies,  \n",
            "Pavement glistens, dreams take flight,  \n",
            "In the rain, the world feels bright.\n",
            "\n",
            "‚Äî Run 2 (temp=1.0) ‚Äî\n",
            "Whispers fall from velvet skies,  \n",
            "Dancing droplets, sweet surprise,  \n",
            "Nature's tears, a soft embrace,  \n",
            "Washing worries, leaving grace.\n",
            "\n",
            "‚Äî Run 3 (temp=1.0) ‚Äî\n",
            "In whispers soft, the raindrops fall,  \n",
            "A symphony of nature's call.  \n",
            "Each droplet dances on the street,  \n",
            "A gentle balm, a cool retreat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "These three poems at temperature = 1.0 show a balance of variety and consistency. Each output uses gentle, predictable imagery like whispers, droplets, and nature, but the phrasing and rhythm shift slightly with each run. This illustrates how the default temperature produces outputs that are creative yet still fairly stable across generations."
      ],
      "metadata": {
        "id": "RYOxSHC2Ib2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature `0.2`"
      ],
      "metadata": {
        "id": "zRqQP76ZzA-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=0.2) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=0.2))\n",
        "    if i < 2:  # no need to sleep after the last run\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3JXl8U1y-q5",
        "outputId": "d549fbea-324b-4327-cd29-8c88de666449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=0.2) ‚Äî\n",
            "Whispers of silver from clouds above,  \n",
            "Dance on the rooftops, a gentle love.  \n",
            "Puddles reflect the sky's soft embrace,  \n",
            "In each drop, a story, a fleeting grace.\n",
            "\n",
            "‚Äî Run 2 (temp=0.2) ‚Äî\n",
            "Whispers fall from silver skies,  \n",
            "Dancing drops in soft reprise,  \n",
            "Nature's tears, a sweet embrace,  \n",
            "Life awakens, finds its grace.\n",
            "\n",
            "‚Äî Run 3 (temp=0.2) ‚Äî\n",
            "Whispers fall from clouds above,  \n",
            "A gentle dance, the earth's sweet love.  \n",
            "Each drop a note in nature's song,  \n",
            "In rain's embrace, we all belong.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anaylsis**\n",
        "\n",
        "At temperature = 0.2, the poems are highly consistent, with repeated imagery like whispers of silver and dancing droplets. The structure and tone stay nearly identical across runs, showing how a low temperature makes the model more deterministic and less creative. The outputs feel polished but with less variety compared to higher settings."
      ],
      "metadata": {
        "id": "4XGSTCf5JalE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature `1.8`"
      ],
      "metadata": {
        "id": "5R14lCUW8Xjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n‚Äî Run {i+1} (temp=1.8) ‚Äî\")\n",
        "    print(system_user_prompt(system_message, user_message, temperature=1.8))\n",
        "    if i < 2:  # no need to sleep after the last run\n",
        "        time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z2pDIIAzWHL",
        "outputId": "b6437f53-79ea-4d8b-d952-467b40549453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚Äî Run 1 (temp=1.8) ‚Äî\n",
            "Silver droplets weave through air,  \n",
            "Dancing lightly, somber fair.  \n",
            "Each whispered patter tells appt sigh,  \n",
            "Nature‚Äôs hymn, as clouds drift by.\n",
            "\n",
            "‚Äî Run 2 (temp=1.8) ‚Äî\n",
            "Soft petals weep beneath the gray,  \n",
            "As whispers of the heavens sway.  \n",
            "Each drop, a gentle poetry grown,  \n",
            "Turning earth‚Äôs cradle to a solace zone.\n",
            "\n",
            "‚Äî Run 3 (temp=1.8) ‚Äî\n",
            "Whispers dance from strumbled skies,  \n",
            "Twinkling droplets lift our sighs.  \n",
            "Each hue bathes earth in glistening hue,  \n",
            "Nature breathes anew‚Äîthrough liquid blue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "At temperature = 1.8, the poems show much more variety and imaginative phrasing, such as calm swarm or dusty dreams. The imagery shifts noticeably between runs, with less repetition and more surprising word choices. This demonstrates how a high temperature boosts creativity and randomness, though it can also lead to less polished or less consistent results.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "9bPIOp_lJk6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Markdown Formatting  \n",
        "\n",
        "So far, we have seen the LLM's raw output. However, we can make our results more readable by asking the model to format responses in **Markdown**. This will help us generate outputs that look cleaner and are easier to interpret inside Colab or on GitHub. This is especially useful when working with structured content such as study guides, rubrics, or summaries.\n",
        "\n",
        "We can create a function called `to_markdown`, which we will call whenever we want to render the model‚Äôs text as formatted Markdown (headings, lists, bold/italics) instead of plain text.\n"
      ],
      "metadata": {
        "id": "p0QO78dcLxyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    # Convert the provided text to Markdown format for better display in Jupyter Notebooks\n",
        "    return Markdown(text)"
      ],
      "metadata": {
        "id": "aEVCoqPhOQvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out with the `encouaring_tips` variable we created earlier!"
      ],
      "metadata": {
        "id": "mWN_i6iTWukY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(encouaring_tips)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "3EDQFXHhwR-D",
        "outputId": "b95c2c61-b2ba-4c06-bfa4-ccd8ca80c05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Absolutely, you‚Äôve got this! Here are three more study tips for your statistics course:\n\n- **Visual Aids:** Create charts or graphs to visualize concepts like normal distribution and correlation to enhance understanding.\n\n- **Study Groups:** Discuss hypothesis testing in study groups to clarify concepts and learn from different perspectives.\n\n- **Practice Problems:** Regularly solve past exams and practice problems focused on probability and statistical inference to build confidence."
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See! Our output is much cleaner!\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "XI551XFMw4-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Forward  \n",
        "\n",
        "Congrats! You now have the basics of prompt engineering. üéâ  \n",
        "Next, we‚Äôll apply these skills to a real use case ‚Äî showing how LLMs can generate an essay, design a rubric, and then grade the essay based on that rubric.  \n"
      ],
      "metadata": {
        "id": "kuF1QiUE7yae"
      }
    }
  ]
}